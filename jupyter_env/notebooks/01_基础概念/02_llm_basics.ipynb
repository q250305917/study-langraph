{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": ["学习目标"]
   },
   "source": [
    "# 🧠 大语言模型(LLM)基础\n",
    "\n",
    "<div class=\"learning-objectives\">\n",
    "<h3>🎯 学习目标</h3>\n",
    "<ul>\n",
    "<li>理解大语言模型的基本概念和工作原理</li>\n",
    "<li>掌握LangChain中不同LLM的使用方法</li>\n",
    "<li>学会配置和优化LLM参数</li>\n",
    "<li>了解LLM的能力限制和最佳实践</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "**⏱️ 预计学习时间**: 45分钟  \n",
    "**📊 难度级别**: <span class=\"badge medium\">⭐⭐⭐☆☆</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["环境初始化"]
   },
   "outputs": [],
   "source": [
    "# 🔧 环境初始化\n",
    "import sys\n",
    "import os\n",
    "import asyncio\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 添加工具路径\n",
    "sys.path.append('../utils')\n",
    "\n",
    "# 加载环境变量\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"🧠 大语言模型基础课程\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 检查必要依赖\n",
    "required_imports = {\n",
    "    'langchain_openai': 'OpenAI LLM集成',\n",
    "    'langchain_anthropic': 'Anthropic Claude集成 (可选)',\n",
    "    'langchain_core': 'LangChain核心组件',\n",
    "    'tiktoken': 'Token计数工具'\n",
    "}\n",
    "\n",
    "available_llms = []\n",
    "for module, description in required_imports.items():\n",
    "    try:\n",
    "        __import__(module)\n",
    "        print(f\"✅ {description}\")\n",
    "        if 'openai' in module:\n",
    "            available_llms.append('OpenAI')\n",
    "        elif 'anthropic' in module:\n",
    "            available_llms.append('Anthropic')\n",
    "    except ImportError:\n",
    "        print(f\"⚠️ {description}: 未安装\")\n",
    "\n",
    "print(f\"\\n📋 可用LLM: {', '.join(available_llms) if available_llms else '需要配置API密钥'}\")\n",
    "\n",
    "# 初始化进度追踪\n",
    "try:\n",
    "    from progress_tracker import start_lesson, complete_section, complete_exercise, get_tracker\n",
    "    \n",
    "    start_lesson(\"02_llm_basics\", \"大语言模型基础\")\n",
    "    tracker = get_tracker()\n",
    "    tracker.set_lesson_info(\"02_llm_basics\", total_sections=6, total_exercises=3)\n",
    "    \n",
    "    print(\"📈 进度追踪已启动\")\n",
    "except ImportError:\n",
    "    def complete_section(name): pass\n",
    "    def complete_exercise(name, score=None): pass\n",
    "    print(\"⚠️ 进度追踪器未加载\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 🤖 什么是大语言模型？\n",
    "\n",
    "**大语言模型(Large Language Model, LLM)** 是一种基于深度学习的AI模型，通过学习大量文本数据来理解和生成人类语言。\n",
    "\n",
    "### 🏗️ LLM的核心特征\n",
    "\n",
    "| 特征 | 描述 | 示例 |\n",
    "|------|------|------|\n",
    "| **大规模参数** | 包含数十亿到数千亿个参数 | GPT-3: 1750亿参数 |\n",
    "| **预训练** | 在大量无标签文本上预训练 | 网页、书籍、文章等 |\n",
    "| **泛化能力** | 能处理多种语言任务 | 翻译、摘要、问答等 |\n",
    "| **上下文理解** | 理解长文本的上下文关系 | 多轮对话、文档理解 |\n",
    "\n",
    "### 🧬 LLM的工作原理\n",
    "\n",
    "```\n",
    "输入文本 → 词汇编码 → 注意力机制 → 神经网络层 → 概率分布 → 输出文本\n",
    "    ↓           ↓           ↓            ↓           ↓\n",
    "  Token化    嵌入向量    上下文理解    特征提取    下一词预测\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["概念演示"]
   },
   "outputs": [],
   "source": [
    "# 🎨 LLM工作流程可视化\n",
    "workflow_html = \"\"\"\n",
    "<div style=\"margin: 20px 0;\">\n",
    "    <h4>🔄 LLM处理流程</h4>\n",
    "    <div style=\"display: flex; justify-content: space-between; align-items: center; \n",
    "                background: linear-gradient(90deg, #f0f9ff 0%, #e0f2fe 100%); \n",
    "                padding: 20px; border-radius: 10px; margin: 15px 0;\">\n",
    "        \n",
    "        <div style=\"text-align: center; min-width: 100px;\">\n",
    "            <div style=\"font-size: 2em; margin-bottom: 5px;\">📝</div>\n",
    "            <strong>输入文本</strong><br>\n",
    "            <small>用户提示词</small>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"font-size: 1.5em; color: #0277bd;\">→</div>\n",
    "        \n",
    "        <div style=\"text-align: center; min-width: 100px;\">\n",
    "            <div style=\"font-size: 2em; margin-bottom: 5px;\">🔤</div>\n",
    "            <strong>Token化</strong><br>\n",
    "            <small>文本分割</small>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"font-size: 1.5em; color: #0277bd;\">→</div>\n",
    "        \n",
    "        <div style=\"text-align: center; min-width: 100px;\">\n",
    "            <div style=\"font-size: 2em; margin-bottom: 5px;\">🧠</div>\n",
    "            <strong>模型处理</strong><br>\n",
    "            <small>神经网络</small>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"font-size: 1.5em; color: #0277bd;\">→</div>\n",
    "        \n",
    "        <div style=\"text-align: center; min-width: 100px;\">\n",
    "            <div style=\"font-size: 2em; margin-bottom: 5px;\">📊</div>\n",
    "            <strong>概率计算</strong><br>\n",
    "            <small>下一词预测</small>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"font-size: 1.5em; color: #0277bd;\">→</div>\n",
    "        \n",
    "        <div style=\"text-align: center; min-width: 100px;\">\n",
    "            <div style=\"font-size: 2em; margin-bottom: 5px;\">💬</div>\n",
    "            <strong>生成文本</strong><br>\n",
    "            <small>最终输出</small>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(workflow_html))\n",
    "\n",
    "# Token概念演示\n",
    "def demonstrate_tokenization():\n",
    "    \"\"\"演示文本Token化过程\"\"\"\n",
    "    \n",
    "    # 如果有tiktoken，展示真实的tokenization\n",
    "    try:\n",
    "        import tiktoken\n",
    "        \n",
    "        # 使用GPT-3.5的编码器\n",
    "        encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "        \n",
    "        test_texts = [\n",
    "            \"Hello, world!\",\n",
    "            \"LangChain是一个强大的框架\",\n",
    "            \"人工智能正在改变世界\"\n",
    "        ]\n",
    "        \n",
    "        print(\"🔤 Token化演示（使用GPT-3.5编码器）:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for text in test_texts:\n",
    "            tokens = encoding.encode(text)\n",
    "            decoded_tokens = [encoding.decode([token]) for token in tokens]\n",
    "            \n",
    "            print(f\"原文: {text}\")\n",
    "            print(f\"Token数: {len(tokens)}\")\n",
    "            print(f\"Token列表: {decoded_tokens}\")\n",
    "            print(f\"Token ID: {tokens}\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"🔤 Token化概念演示（模拟）:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # 简单的模拟tokenization\n",
    "        test_text = \"LangChain是一个强大的AI框架\"\n",
    "        # 简化的分词（实际Token化更复杂）\n",
    "        mock_tokens = [\"Lang\", \"Chain\", \"是\", \"一个\", \"强大\", \"的\", \"AI\", \"框架\"]\n",
    "        \n",
    "        print(f\"原文: {test_text}\")\n",
    "        print(f\"模拟Token: {mock_tokens}\")\n",
    "        print(f\"Token数量: {len(mock_tokens)}\")\n",
    "        print(\"\\n💡 注意: 实际的Token化会考虑子词、标点等复杂规则\")\n",
    "\n",
    "demonstrate_tokenization()\n",
    "\n",
    "complete_section(\"llm_concepts\")\n",
    "print(\"\\n✅ 章节完成：LLM概念\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 🔧 LangChain中的LLM集成\n",
    "\n",
    "LangChain支持多种LLM提供商，让我们学习如何使用它们。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["LLM集成"]
   },
   "outputs": [],
   "source": [
    "# 🌐 多LLM提供商演示\n",
    "def demonstrate_llm_providers():\n",
    "    \"\"\"演示不同LLM提供商的使用\"\"\"\n",
    "    \n",
    "    llm_configs = {}\n",
    "    \n",
    "    print(\"🌐 LLM提供商配置演示\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # 1. OpenAI配置\n",
    "    print(\"\\n1️⃣ OpenAI GPT模型\")\n",
    "    try:\n",
    "        from langchain_openai import ChatOpenAI, OpenAI\n",
    "        \n",
    "        if os.getenv('OPENAI_API_KEY'):\n",
    "            # Chat模型（推荐）\n",
    "            chat_llm = ChatOpenAI(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=0.7,\n",
    "                max_tokens=150,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            # 补全模型\n",
    "            completion_llm = OpenAI(\n",
    "                model=\"gpt-3.5-turbo-instruct\",\n",
    "                temperature=0.5,\n",
    "                max_tokens=100\n",
    "            )\n",
    "            \n",
    "            llm_configs['openai_chat'] = chat_llm\n",
    "            llm_configs['openai_completion'] = completion_llm\n",
    "            \n",
    "            print(\"   ✅ ChatOpenAI配置成功\")\n",
    "            print(\"   ✅ OpenAI补全模型配置成功\")\n",
    "            \n",
    "        else:\n",
    "            print(\"   ⚠️ 需要OPENAI_API_KEY环境变量\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"   ❌ langchain_openai未安装\")\n",
    "    \n",
    "    # 2. Anthropic配置\n",
    "    print(\"\\n2️⃣ Anthropic Claude模型\")\n",
    "    try:\n",
    "        from langchain_anthropic import ChatAnthropic\n",
    "        \n",
    "        if os.getenv('ANTHROPIC_API_KEY'):\n",
    "            claude_llm = ChatAnthropic(\n",
    "                model=\"claude-3-sonnet-20240229\",\n",
    "                temperature=0.7,\n",
    "                max_tokens=150\n",
    "            )\n",
    "            \n",
    "            llm_configs['anthropic'] = claude_llm\n",
    "            print(\"   ✅ Claude配置成功\")\n",
    "        else:\n",
    "            print(\"   ⚠️ 需要ANTHROPIC_API_KEY环境变量\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"   ⚠️ langchain_anthropic未安装（可选）\")\n",
    "    \n",
    "    # 3. 本地模型配置（示例）\n",
    "    print(\"\\n3️⃣ 本地模型配置（示例）\")\n",
    "    try:\n",
    "        from langchain_community.llms import Ollama\n",
    "        \n",
    "        # 注意：需要本地运行Ollama服务\n",
    "        local_llm = Ollama(\n",
    "            model=\"llama2\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        # 不实际测试连接，只是展示配置\n",
    "        print(\"   📝 Ollama配置示例（需要本地安装）\")\n",
    "        print(\"      安装: https://ollama.ai/\")\n",
    "        print(\"      模型: ollama pull llama2\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"   📝 本地模型需要安装 langchain_community\")\n",
    "    \n",
    "    return llm_configs\n",
    "\n",
    "# 运行演示\n",
    "available_llms = demonstrate_llm_providers()\n",
    "\n",
    "# 显示可用的LLM总结\n",
    "if available_llms:\n",
    "    print(f\"\\n📋 本次课程可用LLM: {list(available_llms.keys())}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ 无可用LLM，部分演示将使用模拟数据\")\n",
    "\n",
    "complete_section(\"llm_integration\")\n",
    "print(\"\\n✅ 章节完成：LLM集成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ⚙️ LLM参数调优\n",
    "\n",
    "了解和掌握LLM的关键参数，能够显著影响模型的表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["参数调优"]
   },
   "outputs": [],
   "source": [
    "# ⚙️ LLM参数详解和演示\n",
    "def demonstrate_llm_parameters():\n",
    "    \"\"\"演示LLM的重要参数\"\"\"\n",
    "    \n",
    "    # 参数说明表\n",
    "    params_html = \"\"\"\n",
    "    <div style=\"margin: 20px 0;\">\n",
    "        <h4>⚙️ 核心参数说明</h4>\n",
    "        <table style=\"width: 100%; border-collapse: collapse; font-size: 14px;\">\n",
    "            <thead>\n",
    "                <tr style=\"background-color: #f5f5f5;\">\n",
    "                    <th style=\"border: 1px solid #ddd; padding: 10px; text-align: left;\">参数</th>\n",
    "                    <th style=\"border: 1px solid #ddd; padding: 10px; text-align: left;\">范围</th>\n",
    "                    <th style=\"border: 1px solid #ddd; padding: 10px; text-align: left;\">作用</th>\n",
    "                    <th style=\"border: 1px solid #ddd; padding: 10px; text-align: left;\">建议值</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            <tbody>\n",
    "                <tr>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\"><strong>temperature</strong></td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">0.0 - 2.0</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">控制输出的随机性和创造性</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">事实问答: 0.1-0.3<br>创意写作: 0.7-1.0</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\"><strong>max_tokens</strong></td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">1 - 4096+</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">限制输出长度</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">摘要: 100-200<br>文章: 500-1000</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\"><strong>top_p</strong></td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">0.0 - 1.0</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">核心采样，控制词汇多样性</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">通常: 0.9-1.0</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\"><strong>frequency_penalty</strong></td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">-2.0 - 2.0</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">减少重复词汇</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">避免重复: 0.1-0.5</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\"><strong>presence_penalty</strong></td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">-2.0 - 2.0</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">鼓励新话题</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">话题多样化: 0.1-0.3</td>\n",
    "                </tr>\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(params_html))\n",
    "    \n",
    "    # 实际参数演示\n",
    "    if available_llms:\n",
    "        print(\"\\n🧪 参数效果对比演示\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # 选择一个可用的LLM进行演示\n",
    "        llm_key = list(available_llms.keys())[0]\n",
    "        base_llm = available_llms[llm_key]\n",
    "        \n",
    "        # 测试提示词\n",
    "        test_prompt = \"描述一个未来城市的一天\"\n",
    "        \n",
    "        # 不同temperature设置\n",
    "        temp_configs = [\n",
    "            {\"name\": \"保守型(0.1)\", \"temperature\": 0.1, \"description\": \"输出确定性强，重复性高\"},\n",
    "            {\"name\": \"平衡型(0.7)\", \"temperature\": 0.7, \"description\": \"创造性与一致性平衡\"},\n",
    "            {\"name\": \"创意型(1.2)\", \"temperature\": 1.2, \"description\": \"高创造性，更多变化\"}\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            from langchain_openai import ChatOpenAI\n",
    "            from langchain_core.messages import HumanMessage\n",
    "            \n",
    "            print(f\"使用 {llm_key} 进行temperature对比:\")\n",
    "            print(f\"提示词: '{test_prompt}'\\n\")\n",
    "            \n",
    "            for config in temp_configs:\n",
    "                print(f\"🌡️ {config['name']} - {config['description']}\")\n",
    "                \n",
    "                # 创建配置后的LLM\n",
    "                configured_llm = ChatOpenAI(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    temperature=config['temperature'],\n",
    "                    max_tokens=100\n",
    "                )\n",
    "                \n",
    "                try:\n",
    "                    response = configured_llm.invoke([HumanMessage(content=test_prompt)])\n",
    "                    print(f\"   回复: {response.content[:150]}...\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   演示跳过（需要API密钥）: {str(e)[:50]}...\")\n",
    "                \n",
    "                print()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"参数演示需要API密钥和网络连接\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\n💡 参数效果模拟演示:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        demo_responses = {\n",
    "            \"低temperature(0.1)\": \"未来城市将有高效的交通系统和清洁能源，人们的生活更加便利和环保。\",\n",
    "            \"中temperature(0.7)\": \"在2050年的新海市，晨光透过透明的空气净化穹顶洒向大地，智能飞行器在有序的航道中穿梭...\",\n",
    "            \"高temperature(1.2)\": \"墨绿色的藤蔓缠绕着摩天大楼，全息鲸鱼在云层中游弋，居民们通过意念控制着漂浮的家园...\"\n",
    "        }\n",
    "        \n",
    "        for setting, response in demo_responses.items():\n",
    "            print(f\"🌡️ {setting}:\")\n",
    "            print(f\"   {response}\")\n",
    "            print()\n",
    "\n",
    "demonstrate_llm_parameters()\n",
    "\n",
    "complete_section(\"parameter_tuning\")\n",
    "print(\"✅ 章节完成：参数调优\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 🔄 异步和流式处理\n",
    "\n",
    "学习如何使用异步调用和流式响应来提高用户体验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["异步处理"]
   },
   "outputs": [],
   "source": [
    "# 🔄 异步和流式处理演示\n",
    "async def demonstrate_async_streaming():\n",
    "    \"\"\"演示异步调用和流式处理\"\"\"\n",
    "    \n",
    "    print(\"🔄 异步和流式处理演示\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    if not available_llms:\n",
    "        print(\"📝 演示概念（需要API密钥才能看到实际效果）:\\n\")\n",
    "        \n",
    "        # 模拟异步调用\n",
    "        print(\"1️⃣ 异步调用演示:\")\n",
    "        print(\"   - 可以并发处理多个请求\")\n",
    "        print(\"   - 不阻塞主线程\")\n",
    "        print(\"   - 提高应用响应性\")\n",
    "        \n",
    "        print(\"\\n2️⃣ 流式响应演示:\")\n",
    "        print(\"   - 实时返回生成的文本\")\n",
    "        print(\"   - 减少用户等待时间\")\n",
    "        print(\"   - 更好的交互体验\")\n",
    "        \n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        from langchain_core.messages import HumanMessage\n",
    "        from langchain_core.callbacks import BaseCallbackHandler\n",
    "        import time\n",
    "        \n",
    "        # 1. 异步调用演示\n",
    "        print(\"1️⃣ 异步调用演示\")\n",
    "        \n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=50\n",
    "        )\n",
    "        \n",
    "        # 准备多个请求\n",
    "        questions = [\n",
    "            \"什么是人工智能？\",\n",
    "            \"什么是机器学习？\",\n",
    "            \"什么是深度学习？\"\n",
    "        ]\n",
    "        \n",
    "        # 同步调用时间测试\n",
    "        print(\"\\n⏰ 同步调用（顺序执行）:\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i, question in enumerate(questions):\n",
    "            try:\n",
    "                response = llm.invoke([HumanMessage(content=question)])\n",
    "                print(f\"   Q{i+1}: {response.content[:50]}...\")\n",
    "            except:\n",
    "                print(f\"   Q{i+1}: [模拟回答] 这是关于{question.split('是')[1]}的解释...\")\n",
    "        \n",
    "        sync_time = time.time() - start_time\n",
    "        print(f\"   总耗时: {sync_time:.2f}秒\")\n",
    "        \n",
    "        # 异步调用时间测试\n",
    "        print(\"\\n⚡ 异步调用（并发执行）:\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 创建异步任务\n",
    "        async def ask_question(llm, question, index):\n",
    "            try:\n",
    "                response = await llm.ainvoke([HumanMessage(content=question)])\n",
    "                return f\"Q{index+1}: {response.content[:50]}...\"\n",
    "            except:\n",
    "                return f\"Q{index+1}: [模拟回答] 这是关于{question.split('是')[1]}的解释...\"\n",
    "        \n",
    "        # 并发执行\n",
    "        tasks = [ask_question(llm, q, i) for i, q in enumerate(questions)]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        for result in results:\n",
    "            print(f\"   {result}\")\n",
    "        \n",
    "        async_time = time.time() - start_time\n",
    "        print(f\"   总耗时: {async_time:.2f}秒\")\n",
    "        print(f\"   ⚡ 速度提升: {sync_time/async_time:.1f}x\")\n",
    "        \n",
    "        # 2. 流式响应演示\n",
    "        print(\"\\n2️⃣ 流式响应演示\")\n",
    "        \n",
    "        class StreamingCallback(BaseCallbackHandler):\n",
    "            \"\"\"流式输出回调\"\"\"\n",
    "            def on_llm_new_token(self, token: str, **kwargs):\n",
    "                print(token, end=\"\", flush=True)\n",
    "        \n",
    "        streaming_llm = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=100,\n",
    "            streaming=True,\n",
    "            callbacks=[StreamingCallback()]\n",
    "        )\n",
    "        \n",
    "        print(\"\\n📝 流式生成文本（请观察逐字输出）:\")\n",
    "        print(\"问题: 描述LangChain的主要优势\")\n",
    "        print(\"回答: \", end=\"\")\n",
    "        \n",
    "        try:\n",
    "            response = await streaming_llm.ainvoke(\n",
    "                [HumanMessage(content=\"描述LangChain的主要优势，约50字\")]\n",
    "            )\n",
    "            print(\"\\n\")\n",
    "        except:\n",
    "            # 模拟流式输出\n",
    "            mock_response = \"LangChain提供了模块化的AI应用开发框架，支持多种LLM集成，简化了复杂AI应用的构建过程。\"\n",
    "            for char in mock_response:\n",
    "                print(char, end=\"\", flush=True)\n",
    "                await asyncio.sleep(0.03)  # 模拟打字效果\n",
    "            print(\"\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"异步演示需要API密钥: {e}\")\n",
    "        \n",
    "        # 显示概念说明\n",
    "        concepts_html = \"\"\"\n",
    "        <div style=\"background-color: #f8f9fa; padding: 15px; border-radius: 8px; margin: 15px 0;\">\n",
    "            <h4>💡 异步和流式处理的优势</h4>\n",
    "            <div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 20px;\">\n",
    "                <div>\n",
    "                    <h5 style=\"color: #2196F3;\">🔄 异步处理</h5>\n",
    "                    <ul style=\"font-size: 14px;\">\n",
    "                        <li>并发处理多个请求</li>\n",
    "                        <li>不阻塞用户界面</li>\n",
    "                        <li>提高系统吞吐量</li>\n",
    "                        <li>更好的资源利用</li>\n",
    "                    </ul>\n",
    "                </div>\n",
    "                <div>\n",
    "                    <h5 style=\"color: #4CAF50;\">📡 流式响应</h5>\n",
    "                    <ul style=\"font-size: 14px;\">\n",
    "                        <li>实时显示生成内容</li>\n",
    "                        <li>减少用户等待时间</li>\n",
    "                        <li>提供即时反馈</li>\n",
    "                        <li>改善用户体验</li>\n",
    "                    </ul>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(concepts_html))\n",
    "\n",
    "# 运行异步演示\n",
    "await demonstrate_async_streaming()\n",
    "\n",
    "complete_section(\"async_streaming\")\n",
    "print(\"\\n✅ 章节完成：异步和流式处理\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 💰 成本优化与性能监控\n",
    "\n",
    "了解如何优化LLM使用成本和监控性能指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["成本优化"]
   },
   "outputs": [],
   "source": [
    "# 💰 成本优化和性能监控\n",
    "def demonstrate_cost_optimization():\n",
    "    \"\"\"演示成本优化策略和性能监控\"\"\"\n",
    "    \n",
    "    print(\"💰 LLM成本优化与性能监控\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # 1. 成本结构分析\n",
    "    cost_html = \"\"\"\n",
    "    <div style=\"margin: 20px 0;\">\n",
    "        <h4>💵 主要LLM成本对比（2024年）</h4>\n",
    "        <table style=\"width: 100%; border-collapse: collapse; font-size: 14px;\">\n",
    "            <thead>\n",
    "                <tr style=\"background-color: #f5f5f5;\">\n",
    "                    <th style=\"border: 1px solid #ddd; padding: 10px;\">模型</th>\n",
    "                    <th style=\"border: 1px solid #ddd; padding: 10px;\">输入价格</th>\n",
    "                    <th style=\"border: 1px solid #ddd; padding: 10px;\">输出价格</th>\n",
    "                    <th style=\"border: 1px solid #ddd; padding: 10px;\">适用场景</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            <tbody>\n",
    "                <tr>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">GPT-3.5 Turbo</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">$0.5/1M tokens</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">$1.5/1M tokens</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">通用任务，成本敏感</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">GPT-4</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">$10/1M tokens</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">$30/1M tokens</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">复杂推理，高质量</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">Claude-3 Sonnet</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">$3/1M tokens</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">$15/1M tokens</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">平衡性能和成本</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">本地模型</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">硬件成本</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">电力成本</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 8px;\">隐私敏感，大量使用</td>\n",
    "                </tr>\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(cost_html))\n",
    "    \n",
    "    # 2. Token计算和成本估算\n",
    "    print(\"\\n📊 Token计算和成本估算\")\n",
    "    \n",
    "    def calculate_cost(text: str, model: str = \"gpt-3.5-turbo\"):\n",
    "        \"\"\"计算文本的成本\"\"\"\n",
    "        \n",
    "        # 简化的token计算（实际应该使用tiktoken）\n",
    "        estimated_tokens = len(text.split()) * 1.3  # 粗略估算\n",
    "        \n",
    "        # 价格表（美元/1M tokens）\n",
    "        prices = {\n",
    "            \"gpt-3.5-turbo\": {\"input\": 0.5, \"output\": 1.5},\n",
    "            \"gpt-4\": {\"input\": 10, \"output\": 30},\n",
    "            \"claude-3-sonnet\": {\"input\": 3, \"output\": 15}\n",
    "        }\n",
    "        \n",
    "        if model in prices:\n",
    "            input_cost = (estimated_tokens / 1_000_000) * prices[model][\"input\"]\n",
    "            output_cost = (estimated_tokens / 1_000_000) * prices[model][\"output\"]  # 假设输出长度相近\n",
    "            total_cost = input_cost + output_cost\n",
    "            \n",
    "            return {\n",
    "                \"tokens\": int(estimated_tokens),\n",
    "                \"input_cost\": input_cost,\n",
    "                \"output_cost\": output_cost,\n",
    "                \"total_cost\": total_cost\n",
    "            }\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    # 示例文本\n",
    "    sample_texts = [\n",
    "        \"什么是AI？\",\n",
    "        \"请详细解释机器学习的工作原理，包括监督学习、无监督学习和强化学习的区别。\",\n",
    "        \"编写一个完整的Python程序，实现一个简单的聊天机器人，包括自然语言处理、意图识别和响应生成功能。要求代码结构清晰，包含详细注释。\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n💸 不同文本长度的成本对比:\")\n",
    "    \n",
    "    for i, text in enumerate(sample_texts, 1):\n",
    "        print(f\"\\n📝 示例{i}: {text[:50]}...\")\n",
    "        \n",
    "        for model in [\"gpt-3.5-turbo\", \"gpt-4\", \"claude-3-sonnet\"]:\n",
    "            cost_info = calculate_cost(text, model)\n",
    "            if cost_info:\n",
    "                print(f\"   {model}:\")\n",
    "                print(f\"     - Tokens: ~{cost_info['tokens']}\")\n",
    "                print(f\"     - 成本: ${cost_info['total_cost']:.6f}\")\n",
    "    \n",
    "    # 3. 优化策略\n",
    "    print(\"\\n🎯 成本优化策略\")\n",
    "    \n",
    "    optimization_strategies = [\n",
    "        \"💡 提示词优化: 简洁明确的提示词减少token使用\",\n",
    "        \"🔄 模型选择: 根据任务复杂度选择合适模型\",\n",
    "        \"📏 长度控制: 设置合理的max_tokens限制\",\n",
    "        \"🎯 批量处理: 合并多个相关查询\",\n",
    "        \"💾 结果缓存: 缓存常见查询的结果\",\n",
    "        \"⚖️ 混合策略: 结合多个模型的优势\",\n",
    "        \"📊 监控告警: 设置成本阈值和告警\"\n",
    "    ]\n",
    "    \n",
    "    for strategy in optimization_strategies:\n",
    "        print(f\"   {strategy}\")\n",
    "    \n",
    "    # 4. 性能监控实现\n",
    "    print(\"\\n📈 性能监控实现\")\n",
    "    \n",
    "    class LLMMonitor:\n",
    "        \"\"\"LLM性能监控类\"\"\"\n",
    "        \n",
    "        def __init__(self):\n",
    "            self.calls = []\n",
    "            self.total_tokens = 0\n",
    "            self.total_cost = 0.0\n",
    "        \n",
    "        def log_call(self, model: str, input_tokens: int, output_tokens: int, duration: float, cost: float):\n",
    "            \"\"\"记录API调用\"\"\"\n",
    "            call_info = {\n",
    "                \"timestamp\": time.time(),\n",
    "                \"model\": model,\n",
    "                \"input_tokens\": input_tokens,\n",
    "                \"output_tokens\": output_tokens,\n",
    "                \"total_tokens\": input_tokens + output_tokens,\n",
    "                \"duration\": duration,\n",
    "                \"cost\": cost\n",
    "            }\n",
    "            \n",
    "            self.calls.append(call_info)\n",
    "            self.total_tokens += call_info[\"total_tokens\"]\n",
    "            self.total_cost += cost\n",
    "        \n",
    "        def get_stats(self):\n",
    "            \"\"\"获取统计信息\"\"\"\n",
    "            if not self.calls:\n",
    "                return {\"total_calls\": 0}\n",
    "            \n",
    "            avg_duration = sum(call[\"duration\"] for call in self.calls) / len(self.calls)\n",
    "            avg_tokens = sum(call[\"total_tokens\"] for call in self.calls) / len(self.calls)\n",
    "            \n",
    "            return {\n",
    "                \"total_calls\": len(self.calls),\n",
    "                \"total_tokens\": self.total_tokens,\n",
    "                \"total_cost\": self.total_cost,\n",
    "                \"avg_duration\": avg_duration,\n",
    "                \"avg_tokens\": avg_tokens,\n",
    "                \"cost_per_call\": self.total_cost / len(self.calls)\n",
    "            }\n",
    "    \n",
    "    # 演示监控器使用\n",
    "    monitor = LLMMonitor()\n",
    "    \n",
    "    # 模拟一些API调用\n",
    "    import random\n",
    "    \n",
    "    for i in range(5):\n",
    "        monitor.log_call(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            input_tokens=random.randint(50, 200),\n",
    "            output_tokens=random.randint(30, 150),\n",
    "            duration=random.uniform(0.5, 3.0),\n",
    "            cost=random.uniform(0.001, 0.01)\n",
    "        )\n",
    "    \n",
    "    stats = monitor.get_stats()\n",
    "    \n",
    "    print(\"\\n📊 监控数据示例:\")\n",
    "    print(f\"   总调用次数: {stats['total_calls']}\")\n",
    "    print(f\"   总Token数: {stats['total_tokens']}\")\n",
    "    print(f\"   总成本: ${stats['total_cost']:.4f}\")\n",
    "    print(f\"   平均响应时间: {stats['avg_duration']:.2f}秒\")\n",
    "    print(f\"   平均每次成本: ${stats['cost_per_call']:.4f}\")\n",
    "\n",
    "demonstrate_cost_optimization()\n",
    "\n",
    "complete_section(\"cost_optimization\")\n",
    "print(\"\\n✅ 章节完成：成本优化\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 💪 实践练习\n",
    "\n",
    "通过实际练习来巩固LLM的使用技能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["练习1"]
   },
   "outputs": [],
   "source": [
    "# 🏋️ 练习1: LLM参数调优实验\n",
    "\n",
    "exercise1_html = \"\"\"\n",
    "<div class=\"exercise-box\">\n",
    "    <div class=\"header\">\n",
    "        <h4>🏋️ 练习1: LLM参数调优实验</h4>\n",
    "        <small>难度: ⭐⭐⭐☆☆</small>\n",
    "    </div>\n",
    "    <div class=\"content\">\n",
    "        <p><strong>任务</strong>: 创建一个参数对比实验，测试不同temperature值对创意写作的影响。</p>\n",
    "        <p><strong>要求</strong>:</p>\n",
    "        <ul>\n",
    "            <li>测试至少3个不同的temperature值 (0.1, 0.7, 1.2)</li>\n",
    "            <li>使用相同的创意写作提示词</li>\n",
    "            <li>比较输出的创造性和一致性</li>\n",
    "            <li>分析结果并得出结论</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(exercise1_html))\n",
    "\n",
    "def exercise_1_solution():\n",
    "    \"\"\"练习1: LLM参数调优实验\"\"\"\n",
    "    \n",
    "    print(\"🧪 开始参数调优实验\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # 创意写作提示词\n",
    "    creative_prompt = \"写一个关于时间旅行者在古代遇到困难的短故事开头（50字内）\"\n",
    "    \n",
    "    # 测试不同temperature值\n",
    "    temperature_configs = [\n",
    "        {\"temp\": 0.1, \"name\": \"保守型\", \"expected\": \"较为平实、逻辑性强\"},\n",
    "        {\"temp\": 0.7, \"name\": \"平衡型\", \"expected\": \"创意与逻辑平衡\"},\n",
    "        {\"temp\": 1.2, \"name\": \"创意型\", \"expected\": \"高度创新、想象丰富\"}\n",
    "    ]\n",
    "    \n",
    "    print(f\"📝 测试提示词: {creative_prompt}\\n\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for config in temperature_configs:\n",
    "        print(f\"🌡️ Temperature {config['temp']} ({config['name']})\")\n",
    "        print(f\"   预期特点: {config['expected']}\")\n",
    "        \n",
    "        if available_llms:\n",
    "            try:\n",
    "                from langchain_openai import ChatOpenAI\n",
    "                from langchain_core.messages import HumanMessage\n",
    "                \n",
    "                # 创建配置的LLM\n",
    "                llm = ChatOpenAI(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    temperature=config['temp'],\n",
    "                    max_tokens=80\n",
    "                )\n",
    "                \n",
    "                response = llm.invoke([HumanMessage(content=creative_prompt)])\n",
    "                generated_text = response.content\n",
    "                \n",
    "                print(f\"   生成结果: {generated_text}\")\n",
    "                \n",
    "                # 简单的创意评分（基于词汇多样性和情节复杂度）\n",
    "                words = generated_text.split()\n",
    "                unique_words = len(set(words))\n",
    "                creativity_score = unique_words / len(words) if words else 0\n",
    "                \n",
    "                results.append({\n",
    "                    \"temperature\": config['temp'],\n",
    "                    \"text\": generated_text,\n",
    "                    \"word_count\": len(words),\n",
    "                    \"unique_words\": unique_words,\n",
    "                    \"creativity_score\": creativity_score\n",
    "                })\n",
    "                \n",
    "                print(f\"   词汇多样性: {creativity_score:.2f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   需要API密钥进行实际测试\")\n",
    "                \n",
    "                # 提供模拟结果\n",
    "                mock_results = {\n",
    "                    0.1: \"李明穿越到明朝，发现自己的现代装扮引起了村民的围观和怀疑。\",\n",
    "                    0.7: \"时空裂缝将艾米送到了中世纪的城堡，她的智能手表在烛光下显得格外醒目。\",\n",
    "                    1.2: \"墨色旋涡吞噬了杰克，当他睁眼时，翡翠色的龙正凝视着他手中闪烁的量子装置。\"\n",
    "                }\n",
    "                \n",
    "                mock_text = mock_results.get(config['temp'], \"模拟生成的创意文本\")\n",
    "                print(f\"   模拟结果: {mock_text}\")\n",
    "                \n",
    "                words = mock_text.split()\n",
    "                creativity_score = len(set(words)) / len(words)\n",
    "                \n",
    "                results.append({\n",
    "                    \"temperature\": config['temp'],\n",
    "                    \"text\": mock_text,\n",
    "                    \"creativity_score\": creativity_score\n",
    "                })\n",
    "                \n",
    "                print(f\"   模拟创意分数: {creativity_score:.2f}\")\n",
    "        \n",
    "        else:\n",
    "            # 完全模拟的结果\n",
    "            mock_results = {\n",
    "                0.1: \"李明穿越到明朝，发现自己的现代装扮引起了村民的围观。\",\n",
    "                0.7: \"时空裂缝将艾米送到中世纪，她的智能手表在烛光下闪闪发光。\",\n",
    "                1.2: \"墨色漩涡吞噬杰克，翡翠龙凝视着他手中的量子装置，时间在此刻静止。\"\n",
    "            }\n",
    "            \n",
    "            mock_text = mock_results[config['temp']]\n",
    "            print(f\"   模拟结果: {mock_text}\")\n",
    "            \n",
    "            results.append({\n",
    "                \"temperature\": config['temp'],\n",
    "                \"text\": mock_text,\n",
    "                \"creativity_score\": config['temp']  # 简化：temperature越高创意分越高\n",
    "            })\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # 分析结果\n",
    "    print(\"📊 实验结果分析:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    if results:\n",
    "        # 按创意分数排序\n",
    "        sorted_results = sorted(results, key=lambda x: x['creativity_score'])\n",
    "        \n",
    "        print(\"创意程度排序 (低到高):\")\n",
    "        for result in sorted_results:\n",
    "            print(f\"   Temperature {result['temperature']}: {result['creativity_score']:.2f}\")\n",
    "        \n",
    "        print(\"\\n💡 结论:\")\n",
    "        if sorted_results[-1]['temperature'] > sorted_results[0]['temperature']:\n",
    "            print(\"   ✅ 验证了temperature越高，输出越有创意\")\n",
    "        else:\n",
    "            print(\"   ⚠️ 结果表明创意不完全取决于temperature\")\n",
    "        \n",
    "        print(\"   📝 建议: 根据具体任务选择合适的temperature值\")\n",
    "        print(\"   📝 事实性任务: 0.1-0.3\")\n",
    "        print(\"   📝 创意任务: 0.7-1.2\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 运行练习1\n",
    "exercise1_results = exercise_1_solution()\n",
    "\n",
    "# 评估练习完成情况\n",
    "if len(exercise1_results) >= 3:\n",
    "    # 检查是否测试了不同的temperature值\n",
    "    temps = [r['temperature'] for r in exercise1_results]\n",
    "    has_variety = max(temps) - min(temps) >= 1.0\n",
    "    \n",
    "    if has_variety:\n",
    "        print(\"\\n🎉 练习1完成优秀！\")\n",
    "        print(\"   - 成功测试了多个temperature值\")\n",
    "        print(\"   - 进行了结果分析和比较\")\n",
    "        print(\"   - 得出了合理结论\")\n",
    "        complete_exercise(\"exercise_1\", 95)\n",
    "    else:\n",
    "        print(\"\\n✅ 练习1基本完成\")\n",
    "        print(\"   建议: 尝试更大的temperature差异\")\n",
    "        complete_exercise(\"exercise_1\", 80)\n",
    "else:\n",
    "    print(\"\\n⚠️ 练习1需要完善\")\n",
    "    complete_exercise(\"exercise_1\", 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["练习2"]
   },
   "outputs": [],
   "source": [
    "# 🏋️ 练习2: 多模型性能对比\n",
    "\n",
    "exercise2_html = \"\"\"\n",
    "<div class=\"exercise-box\">\n",
    "    <div class=\"header\">\n",
    "        <h4>🏋️ 练习2: 多模型性能对比</h4>\n",
    "        <small>难度: ⭐⭐⭐⭐☆</small>\n",
    "    </div>\n",
    "    <div class=\"content\">\n",
    "        <p><strong>任务</strong>: 创建一个多模型对比系统，测试不同模型在相同任务上的表现。</p>\n",
    "        <p><strong>要求</strong>:</p>\n",
    "        <ul>\n",
    "            <li>对比至少2种不同模型（如GPT-3.5 vs GPT-4）</li>\n",
    "            <li>测试3种不同类型的任务（事实问答、创意写作、逻辑推理）</li>\n",
    "            <li>记录响应时间、质量评分</li>\n",
    "            <li>提供综合评估和使用建议</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(exercise2_html))\n",
    "\n",
    "def exercise_2_solution():\n",
    "    \"\"\"练习2: 多模型性能对比\"\"\"\n",
    "    \n",
    "    print(\"🔬 多模型性能对比实验\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # 定义测试任务\n",
    "    test_tasks = [\n",
    "        {\n",
    "            \"type\": \"事实问答\",\n",
    "            \"prompt\": \"北京的人口大约是多少？请提供2023年的数据。\",\n",
    "            \"evaluation_criteria\": [\"准确性\", \"时效性\", \"简洁性\"]\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"创意写作\",\n",
    "            \"prompt\": \"写一首关于人工智能与人类友谊的现代诗，4行。\",\n",
    "            \"evaluation_criteria\": [\"创意性\", \"韵律感\", \"主题契合\"]\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"逻辑推理\",\n",
    "            \"prompt\": \"如果A比B高，B比C高，C比D高，且D身高170cm，那么A的身高最少是多少？\",\n",
    "            \"evaluation_criteria\": [\"逻辑正确性\", \"推理过程\", \"结论明确性\"]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # 定义模型配置\n",
    "    model_configs = [\n",
    "        {\n",
    "            \"name\": \"GPT-3.5-Turbo\",\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"cost_per_1k\": 0.002,\n",
    "            \"description\": \"快速、经济的通用模型\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"GPT-4\",\n",
    "            \"model\": \"gpt-4\",\n",
    "            \"cost_per_1k\": 0.03,\n",
    "            \"description\": \"高质量、强推理能力\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for task in test_tasks:\n",
    "        print(f\"\\n📋 测试任务: {task['type']}\")\n",
    "        print(f\"   提示词: {task['prompt']}\")\n",
    "        print(f\"   评估标准: {', '.join(task['evaluation_criteria'])}\")\n",
    "        print()\n",
    "        \n",
    "        task_results = []\n",
    "        \n",
    "        for model_config in model_configs:\n",
    "            print(f\"🤖 模型: {model_config['name']}\")\n",
    "            \n",
    "            if available_llms:\n",
    "                try:\n",
    "                    from langchain_openai import ChatOpenAI\n",
    "                    from langchain_core.messages import HumanMessage\n",
    "                    import time\n",
    "                    \n",
    "                    # 创建模型实例\n",
    "                    llm = ChatOpenAI(\n",
    "                        model=model_config['model'],\n",
    "                        temperature=0.7,\n",
    "                        max_tokens=150\n",
    "                    )\n",
    "                    \n",
    "                    # 记录响应时间\n",
    "                    start_time = time.time()\n",
    "                    response = llm.invoke([HumanMessage(content=task['prompt'])])\n",
    "                    response_time = time.time() - start_time\n",
    "                    \n",
    "                    result_text = response.content\n",
    "                    \n",
    "                    print(f\"   响应时间: {response_time:.2f}秒\")\n",
    "                    print(f\"   响应内容: {result_text[:100]}...\")\n",
    "                    \n",
    "                    # 简单的质量评分（实际应该更复杂）\n",
    "                    quality_score = min(95, 70 + len(result_text.split()) * 2)  # 基于长度的简化评分\n",
    "                    \n",
    "                    task_results.append({\n",
    "                        \"model\": model_config['name'],\n",
    "                        \"response_time\": response_time,\n",
    "                        \"response\": result_text,\n",
    "                        \"quality_score\": quality_score,\n",
    "                        \"estimated_cost\": len(result_text.split()) * model_config['cost_per_1k'] / 1000\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   需要API密钥: {str(e)[:50]}...\")\n",
    "                    \n",
    "                    # 模拟结果\n",
    "                    mock_responses = {\n",
    "                        \"GPT-3.5-Turbo\": {\n",
    "                            \"事实问答\": \"北京市2023年常住人口约为2185万人。\",\n",
    "                            \"创意写作\": \"硅芯与血肉心，共舞在数字星空，\\n算法温柔如春风，友谊之花永盛开。\",\n",
    "                            \"逻辑推理\": \"由于A>B>C>D，且D=170cm，所以A至少要比D高3cm以上，即A≥173cm。\"\n",
    "                        },\n",
    "                        \"GPT-4\": {\n",
    "                            \"事实问答\": \"根据最新统计，北京市2023年常住人口约为2185万人，其中户籍人口约1400万人。\",\n",
    "                            \"创意写作\": \"代码与灵魂交织舞，\\n智慧之光照人心，\\n金属手握肉身掌，\\n永恒友谊胜黄金。\",\n",
    "                            \"逻辑推理\": \"设D=170cm。由条件A>B>C>D可知，A至少需要比D高，但题目问最少高度，考虑到'比...高'意味着严格大于，所以A>170cm。理论上A的最小值接近但大于170cm。\"\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    mock_response = mock_responses[model_config['name']][task['type']]\n",
    "                    mock_time = 1.5 if model_config['name'] == \"GPT-3.5-Turbo\" else 2.8\n",
    "                    mock_quality = 85 if model_config['name'] == \"GPT-3.5-Turbo\" else 92\n",
    "                    \n",
    "                    print(f\"   模拟响应时间: {mock_time:.2f}秒\")\n",
    "                    print(f\"   模拟响应: {mock_response}\")\n",
    "                    print(f\"   模拟质量分数: {mock_quality}/100\")\n",
    "                    \n",
    "                    task_results.append({\n",
    "                        \"model\": model_config['name'],\n",
    "                        \"response_time\": mock_time,\n",
    "                        \"response\": mock_response,\n",
    "                        \"quality_score\": mock_quality,\n",
    "                        \"estimated_cost\": len(mock_response.split()) * model_config['cost_per_1k'] / 1000\n",
    "                    })\n",
    "            \n",
    "            else:\n",
    "                # 纯模拟结果\n",
    "                mock_data = {\n",
    "                    \"GPT-3.5-Turbo\": {\"time\": 1.2, \"quality\": 82, \"response\": \"模拟GPT-3.5响应\"},\n",
    "                    \"GPT-4\": {\"time\": 2.5, \"quality\": 91, \"response\": \"模拟GPT-4高质量响应\"}\n",
    "                }\n",
    "                \n",
    "                data = mock_data[model_config['name']]\n",
    "                print(f\"   模拟数据 - 时间: {data['time']}s, 质量: {data['quality']}/100\")\n",
    "                \n",
    "                task_results.append({\n",
    "                    \"model\": model_config['name'],\n",
    "                    \"response_time\": data['time'],\n",
    "                    \"quality_score\": data['quality'],\n",
    "                    \"response\": data['response']\n",
    "                })\n",
    "            \n",
    "            print()\n",
    "        \n",
    "        results.append({\n",
    "            \"task_type\": task['type'],\n",
    "            \"results\": task_results\n",
    "        })\n",
    "    \n",
    "    # 综合分析\n",
    "    print(\"\\n📊 综合分析报告\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # 按模型汇总性能\n",
    "    model_summary = {}\n",
    "    \n",
    "    for model_config in model_configs:\n",
    "        model_name = model_config['name']\n",
    "        model_summary[model_name] = {\n",
    "            \"avg_time\": 0,\n",
    "            \"avg_quality\": 0,\n",
    "            \"total_cost\": 0,\n",
    "            \"task_count\": 0\n",
    "        }\n",
    "    \n",
    "    for task_result in results:\n",
    "        for result in task_result['results']:\n",
    "            model_name = result['model']\n",
    "            summary = model_summary[model_name]\n",
    "            \n",
    "            summary['avg_time'] += result['response_time']\n",
    "            summary['avg_quality'] += result['quality_score']\n",
    "            summary['total_cost'] += result.get('estimated_cost', 0)\n",
    "            summary['task_count'] += 1\n",
    "    \n",
    "    # 计算平均值\n",
    "    for model_name, summary in model_summary.items():\n",
    "        if summary['task_count'] > 0:\n",
    "            summary['avg_time'] /= summary['task_count']\n",
    "            summary['avg_quality'] /= summary['task_count']\n",
    "    \n",
    "    # 显示对比结果\n",
    "    print(\"🏆 模型性能对比:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    for model_name, summary in model_summary.items():\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"   平均响应时间: {summary['avg_time']:.2f}秒\")\n",
    "        print(f\"   平均质量分数: {summary['avg_quality']:.1f}/100\")\n",
    "        print(f\"   估算成本: ${summary['total_cost']:.6f}\")\n",
    "    \n",
    "    # 使用建议\n",
    "    print(\"\\n💡 使用建议:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    best_quality = max(model_summary.values(), key=lambda x: x['avg_quality'])\n",
    "    fastest = min(model_summary.values(), key=lambda x: x['avg_time'])\n",
    "    cheapest = min(model_summary.values(), key=lambda x: x['total_cost'])\n",
    "    \n",
    "    # 找到对应的模型名称\n",
    "    for name, data in model_summary.items():\n",
    "        if data == best_quality:\n",
    "            print(f\"🎯 质量最佳: {name} (分数: {data['avg_quality']:.1f})\")\n",
    "        if data == fastest:\n",
    "            print(f\"⚡ 速度最快: {name} (时间: {data['avg_time']:.2f}s)\")\n",
    "        if data == cheapest:\n",
    "            print(f\"💰 成本最低: {name} (成本: ${data['total_cost']:.6f})\")\n",
    "    \n",
    "    print(\"\\n📝 应用场景建议:\")\n",
    "    print(\"   • 快速响应需求 → 选择速度最快的模型\")\n",
    "    print(\"   • 高质量要求 → 选择质量最佳的模型\")\n",
    "    print(\"   • 大量调用 → 选择成本最低的模型\")\n",
    "    print(\"   • 平衡需求 → 综合考虑质量、速度、成本\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 运行练习2\n",
    "exercise2_results = exercise_2_solution()\n",
    "\n",
    "# 评估练习完成情况\n",
    "if len(exercise2_results) >= 3:  # 至少3个任务\n",
    "    # 检查是否对比了多个模型\n",
    "    models_tested = set()\n",
    "    for task_result in exercise2_results:\n",
    "        for result in task_result['results']:\n",
    "            models_tested.add(result['model'])\n",
    "    \n",
    "    if len(models_tested) >= 2:\n",
    "        print(\"\\n🏅 练习2完成卓越！\")\n",
    "        print(\"   - 成功对比了多个模型\")\n",
    "        print(\"   - 测试了多种任务类型\")\n",
    "        print(\"   - 提供了综合分析和建议\")\n",
    "        complete_exercise(\"exercise_2\", 98)\n",
    "    else:\n",
    "        print(\"\\n✅ 练习2基本完成\")\n",
    "        print(\"   建议: 增加更多模型对比\")\n",
    "        complete_exercise(\"exercise_2\", 85)\n",
    "else:\n",
    "    print(\"\\n⚠️ 练习2需要完善\")\n",
    "    complete_exercise(\"exercise_2\", 70)\n",
    "\n",
    "complete_section(\"practical_exercises\")\n",
    "print(\"\\n✅ 章节完成：实践练习\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 课程总结与进度\n",
    "\n",
    "恭喜你完成了大语言模型基础课程！让我们回顾一下学习成果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": ["课程总结"]
   },
   "outputs": [],
   "source": [
    "# 📈 课程总结和进度展示\n",
    "try:\n",
    "    from progress_tracker import get_tracker, end_lesson\n",
    "    \n",
    "    tracker = get_tracker()\n",
    "    lesson_progress = tracker.get_lesson_progress(\"02_llm_basics\")\n",
    "    overall_progress = tracker.get_overall_progress()\n",
    "    \n",
    "    # 课程总结\n",
    "    summary_html = f\"\"\"\n",
    "    <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 25px; border-radius: 15px; margin: 20px 0;\">\n",
    "        <h3 style=\"margin-top: 0; text-align: center;\">🧠 LLM基础课程完成总结</h3>\n",
    "        \n",
    "        <div style=\"display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin: 20px 0;\">\n",
    "            <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px; text-align: center;\">\n",
    "                <div style=\"font-size: 2.5em; margin-bottom: 10px;\">📚</div>\n",
    "                <div style=\"font-size: 1.8em; font-weight: bold;\">{lesson_progress['completed_sections']}/{lesson_progress['total_sections']}</div>\n",
    "                <div>章节完成</div>\n",
    "            </div>\n",
    "            <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px; text-align: center;\">\n",
    "                <div style=\"font-size: 2.5em; margin-bottom: 10px;\">💪</div>\n",
    "                <div style=\"font-size: 1.8em; font-weight: bold;\">{lesson_progress['completed_exercises']}/{lesson_progress['total_exercises']}</div>\n",
    "                <div>练习完成</div>\n",
    "            </div>\n",
    "            <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px; text-align: center;\">\n",
    "                <div style=\"font-size: 2.5em; margin-bottom: 10px;\">🎯</div>\n",
    "                <div style=\"font-size: 1.8em; font-weight: bold;\">{lesson_progress['progress_percentage']:.0f}%</div>\n",
    "                <div>完成率</div>\n",
    "            </div>\n",
    "            <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px; text-align: center;\">\n",
    "                <div style=\"font-size: 2.5em; margin-bottom: 10px;\">⏱️</div>\n",
    "                <div style=\"font-size: 1.8em; font-weight: bold;\">{lesson_progress['total_time_minutes']:.0f}</div>\n",
    "                <div>学习分钟</div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(summary_html))\n",
    "    \n",
    "    # 学习成果展示\n",
    "    achievements_html = \"\"\"\n",
    "    <div style=\"background-color: #f8f9fa; padding: 20px; border-radius: 10px; margin: 15px 0;\">\n",
    "        <h4 style=\"color: #2c3e50; margin-top: 0;\">🎯 你已经掌握的技能</h4>\n",
    "        <div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 20px;\">\n",
    "            <div>\n",
    "                <h5 style=\"color: #27ae60;\">📖 理论知识</h5>\n",
    "                <ul style=\"line-height: 1.8;\">\n",
    "                    <li>✅ LLM的基本概念和工作原理</li>\n",
    "                    <li>✅ Token化和文本处理机制</li>\n",
    "                    <li>✅ 不同LLM提供商的特点</li>\n",
    "                    <li>✅ 成本结构和优化策略</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            <div>\n",
    "                <h5 style=\"color: #e74c3c;\">🛠️ 实践技能</h5>\n",
    "                <ul style=\"line-height: 1.8;\">\n",
    "                    <li>✅ 配置和使用多种LLM</li>\n",
    "                    <li>✅ 参数调优和性能优化</li>\n",
    "                    <li>✅ 异步调用和流式处理</li>\n",
    "                    <li>✅ 性能监控和成本控制</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(achievements_html))\n",
    "    \n",
    "    # 显示成就\n",
    "    achievements = tracker.get_achievements()\n",
    "    recent_achievements = [a for a in achievements if a.unlocked][-2:]  # 最近2个成就\n",
    "    \n",
    "    if recent_achievements:\n",
    "        achievements_display = \"<div style='margin: 15px 0;'><h4>🏆 最新解锁成就</h4><div style='display: flex; gap: 15px; flex-wrap: wrap;'>\"\n",
    "        \n",
    "        for achievement in recent_achievements:\n",
    "            achievements_display += f\"\"\"\n",
    "            <div style=\"border: 2px solid #FFD700; border-radius: 10px; padding: 15px; background: linear-gradient(135deg, #fff9c4 0%, #fff8a1 100%); min-width: 180px; text-align: center;\">\n",
    "                <div style=\"font-size: 32px; margin-bottom: 8px;\">{achievement.icon}</div>\n",
    "                <div style=\"font-weight: bold; color: #b8860b; margin-bottom: 5px;\">{achievement.name}</div>\n",
    "                <div style=\"font-size: 13px; color: #8b7355;\">{achievement.description}</div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        achievements_display += \"</div></div>\"\n",
    "        display(HTML(achievements_display))\n",
    "    \n",
    "    # 下一步学习建议\n",
    "    next_steps_html = \"\"\"\n",
    "    <div style=\"background: linear-gradient(135deg, #74b9ff 0%, #0984e3 100%); color: white; padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "        <h4 style=\"margin-top: 0;\">🚀 下一步学习路径</h4>\n",
    "        \n",
    "        <div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 15px;\">\n",
    "            <div>\n",
    "                <h5 style=\"margin-bottom: 10px;\">📚 推荐课程</h5>\n",
    "                <ul style=\"line-height: 1.6; margin: 0; padding-left: 20px;\">\n",
    "                    <li><strong>03_prompts_templates.ipynb</strong><br>掌握高级提示词技巧</li>\n",
    "                    <li><strong>02_核心组件/01_chains_introduction.ipynb</strong><br>学习链式组合</li>\n",
    "                    <li><strong>02_核心组件/02_agents_basics.ipynb</strong><br>探索智能代理</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            <div>\n",
    "                <h5 style=\"margin-bottom: 10px;\">💡 学习建议</h5>\n",
    "                <ul style=\"line-height: 1.6; margin: 0; padding-left: 20px;\">\n",
    "                    <li>每天坚持学习30-60分钟</li>\n",
    "                    <li>多动手实践，尝试不同参数</li>\n",
    "                    <li>建立自己的代码片段库</li>\n",
    "                    <li>关注LLM领域的最新发展</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(next_steps_html))\n",
    "    \n",
    "    # 结束课程\n",
    "    end_lesson()\n",
    "    \n",
    "    print(\"🎉 恭喜完成大语言模型基础课程！\")\n",
    "    print(\"📈 你的AI开发技能又提升了一个层次！\")\n",
    "    \n",
    "except ImportError:\n",
    "    # 简化版进度显示\n",
    "    print(\"🧠 大语言模型基础课程 - 完成总结\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"✅ 学习章节: 6/6\")\n",
    "    print(\"✅ 完成练习: 2/2\")\n",
    "    print(\"✅ 掌握技能: LLM配置、参数调优、性能优化\")\n",
    "    print(\"✅ 实践能力: 多模型对比、成本控制\")\n",
    "    print(\"\\n🎉 恭喜完成大语言模型基础课程！\")\n",
    "    print(\"📚 建议继续学习：提示词模板和链式组合\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎊 课程总结\n",
    "\n",
    "### 🌟 核心收获\n",
    "\n",
    "通过本课程，你已经系统掌握了：\n",
    "\n",
    "1. **🧠 LLM核心概念** - 深入理解大语言模型的工作原理和技术特点\n",
    "2. **🔧 实践技能** - 熟练配置和使用多种LLM提供商的服务\n",
    "3. **⚙️ 参数调优** - 掌握关键参数对模型输出的影响和优化策略\n",
    "4. **🚀 高级特性** - 学会使用异步调用、流式响应等提升用户体验\n",
    "5. **💰 成本控制** - 了解成本结构并实施有效的优化措施\n",
    "\n",
    "### 📚 技能清单\n",
    "\n",
    "✅ **模型选择** - 根据任务需求选择最适合的LLM  \n",
    "✅ **参数配置** - 熟练调节temperature、max_tokens等关键参数  \n",
    "✅ **性能优化** - 实现异步调用和流式处理提升响应速度  \n",
    "✅ **成本管理** - 监控使用量并优化成本效益  \n",
    "✅ **质量评估** - 建立评估体系对比不同模型性能  \n",
    "\n",
    "### 🛤️ 学习路径建议\n",
    "\n",
    "现在你已经具备了扎实的LLM基础，建议按以下路径继续深入：\n",
    "\n",
    "1. **提示词工程** → `03_prompts_templates.ipynb`\n",
    "2. **链式组合** → `02_核心组件/01_chains_introduction.ipynb`  \n",
    "3. **智能代理** → `02_核心组件/02_agents_basics.ipynb`\n",
    "4. **记忆系统** → `02_核心组件/03_memory_systems.ipynb`\n",
    "\n",
    "### 💡 持续学习\n",
    "\n",
    "LLM技术发展迅速，建议：\n",
    "- 🔍 关注最新模型发布和技术进展\n",
    "- 🛠️ 多参与实际项目练习\n",
    "- 👥 加入AI开发者社区交流\n",
    "- 📖 持续阅读相关论文和文档\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: center; margin: 30px 0; padding: 20px; background: linear-gradient(45deg, #ff9a9e, #fecfef, #fecfef); border-radius: 15px;\">\n",
    "<h3 style=\"margin: 0; color: #2c3e50;\">🎓 你已经成为LLM应用开发者！</h3>\n",
    "<p style=\"margin: 15px 0 0 0; color: #34495e; font-size: 16px;\">继续探索AI的无限可能吧！</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}