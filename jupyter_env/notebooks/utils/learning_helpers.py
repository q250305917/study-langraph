#!/usr/bin/env python3
"""
LangChainå­¦ä¹ è¾…åŠ©å·¥å…·ç±»

æä¾›å­¦ä¹ è¿‡ç¨‹ä¸­å¸¸ç”¨çš„è¾…åŠ©åŠŸèƒ½ï¼ŒåŒ…æ‹¬ä»£ç ç¤ºä¾‹ã€è°ƒè¯•å·¥å…·ã€æ€§èƒ½ç›‘æ§ç­‰ã€‚
"""

import time
import json
import logging
import functools
from typing import Dict, List, Any, Optional, Callable
from datetime import datetime, timedelta
import inspect
import sys
import traceback

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class CodeExecutionTimer:
    """ä»£ç æ‰§è¡Œæ—¶é—´è®¡æ—¶å™¨"""
    
    def __init__(self, description: str = ""):
        self.description = description
        self.start_time = None
        self.end_time = None
        self.execution_time = None
    
    def __enter__(self):
        """è¿›å…¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        self.start_time = time.time()
        if self.description:
            print(f"â±ï¸ å¼€å§‹æ‰§è¡Œ: {self.description}")
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """é€€å‡ºä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        self.end_time = time.time()
        self.execution_time = self.end_time - self.start_time
        
        if exc_type is None:
            print(f"âœ… æ‰§è¡Œå®Œæˆ: {self.description if self.description else 'ä»£ç å—'} "
                  f"è€—æ—¶ {self.execution_time:.3f} ç§’")
        else:
            print(f"âŒ æ‰§è¡Œå¤±è´¥: {self.description if self.description else 'ä»£ç å—'} "
                  f"è€—æ—¶ {self.execution_time:.3f} ç§’")
            print(f"é”™è¯¯ç±»å‹: {exc_type.__name__}")
            print(f"é”™è¯¯ä¿¡æ¯: {exc_val}")
    
    def get_execution_time(self) -> float:
        """è·å–æ‰§è¡Œæ—¶é—´"""
        return self.execution_time if self.execution_time else 0.0

def time_execution(description: str = ""):
    """è£…é¥°å™¨ï¼šè‡ªåŠ¨è®¡æ—¶å‡½æ•°æ‰§è¡Œæ—¶é—´"""
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            func_desc = description or f"å‡½æ•° {func.__name__}"
            with CodeExecutionTimer(func_desc):
                return func(*args, **kwargs)
        return wrapper
    return decorator

class LangChainDebugger:
    """LangChainè°ƒè¯•è¾…åŠ©å·¥å…·"""
    
    @staticmethod
    def inspect_chain_components(chain, verbose: bool = True):
        """æ£€æŸ¥Chainçš„ç»„æˆéƒ¨åˆ†"""
        print("ğŸ” Chainç»„ä»¶æ£€æŸ¥")
        print("=" * 40)
        
        # æ£€æŸ¥Chainç±»å‹
        chain_type = type(chain).__name__
        print(f"Chainç±»å‹: {chain_type}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰input_variables
        if hasattr(chain, 'input_variables'):
            print(f"è¾“å…¥å˜é‡: {chain.input_variables}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰output_variables
        if hasattr(chain, 'output_variables'):
            print(f"è¾“å‡ºå˜é‡: {chain.output_variables}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰memory
        if hasattr(chain, 'memory') and chain.memory:
            print(f"è®°å¿†ç³»ç»Ÿ: {type(chain.memory).__name__}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰verboseè®¾ç½®
        if hasattr(chain, 'verbose'):
            print(f"è¯¦ç»†æ¨¡å¼: {chain.verbose}")
        
        if verbose:
            # å°è¯•è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯
            try:
                chain_dict = chain.dict() if hasattr(chain, 'dict') else {}
                if chain_dict:
                    print(f"\\nè¯¦ç»†é…ç½®:")
                    for key, value in chain_dict.items():
                        if key not in ['llm', 'memory']:  # é¿å…æ‰“å°å¤æ‚å¯¹è±¡
                            print(f"  {key}: {value}")
            except Exception as e:
                print(f"æ— æ³•è·å–è¯¦ç»†é…ç½®: {e}")
    
    @staticmethod
    def inspect_agent_tools(agent_executor, verbose: bool = True):
        """æ£€æŸ¥Agentçš„å·¥å…·é…ç½®"""
        print("ğŸ› ï¸ Agentå·¥å…·æ£€æŸ¥")
        print("=" * 40)
        
        if hasattr(agent_executor, 'tools'):
            tools = agent_executor.tools
            print(f"å·¥å…·æ•°é‡: {len(tools)}")
            
            for i, tool in enumerate(tools, 1):
                print(f"\\nå·¥å…·{i}: {tool.name}")
                print(f"  æè¿°: {tool.description}")
                
                if hasattr(tool, 'args_schema') and tool.args_schema:
                    print(f"  å‚æ•°æ¨¡å¼: {tool.args_schema}")
                
                if verbose and hasattr(tool, 'func'):
                    # è·å–å‡½æ•°ç­¾å
                    try:
                        sig = inspect.signature(tool.func)
                        print(f"  å‡½æ•°ç­¾å: {sig}")
                    except Exception:
                        pass
        
        # æ£€æŸ¥Agenté…ç½®
        if hasattr(agent_executor, 'agent'):
            agent = agent_executor.agent
            print(f"\\nAgentç±»å‹: {type(agent).__name__}")
            
            if hasattr(agent_executor, 'max_iterations'):
                print(f"æœ€å¤§è¿­ä»£æ¬¡æ•°: {agent_executor.max_iterations}")
    
    @staticmethod
    def trace_execution(func: Callable, *args, **kwargs):
        """è·Ÿè¸ªå‡½æ•°æ‰§è¡Œè¿‡ç¨‹"""
        print(f"ğŸ” å¼€å§‹è·Ÿè¸ªæ‰§è¡Œ: {func.__name__}")
        print("=" * 50)
        
        # è®°å½•è¾“å…¥å‚æ•°
        print("ğŸ“¥ è¾“å…¥å‚æ•°:")
        if args:
            print(f"  ä½ç½®å‚æ•°: {args}")
        if kwargs:
            print(f"  å…³é”®å­—å‚æ•°: {kwargs}")
        
        try:
            # æ‰§è¡Œå‡½æ•°
            start_time = time.time()
            result = func(*args, **kwargs)
            end_time = time.time()
            
            # è®°å½•ç»“æœ
            print(f"\\nğŸ“¤ æ‰§è¡Œç»“æœ:")
            print(f"  è¿”å›å€¼ç±»å‹: {type(result).__name__}")
            print(f"  æ‰§è¡Œæ—¶é—´: {end_time - start_time:.3f} ç§’")
            
            # å¦‚æœç»“æœæ˜¯å­—å…¸æˆ–æœ‰åˆç†çš„å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œæ˜¾ç¤ºéƒ¨åˆ†å†…å®¹
            if isinstance(result, dict):
                print(f"  ç»“æœé”®: {list(result.keys())}")
            elif isinstance(result, str) and len(result) > 100:
                print(f"  ç»“æœé¢„è§ˆ: {result[:100]}...")
            else:
                print(f"  ç»“æœ: {result}")
            
            return result
            
        except Exception as e:
            print(f"\\nâŒ æ‰§è¡Œå¤±è´¥:")
            print(f"  é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"  é”™è¯¯ä¿¡æ¯: {e}")
            print(f"  é”™è¯¯å †æ ˆ:")
            traceback.print_exc()
            raise

class LearningMetrics:
    """å­¦ä¹ æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self):
        self.metrics = {
            'execution_times': [],
            'success_count': 0,
            'error_count': 0,
            'tool_usage': {},
            'session_start': datetime.now()
        }
    
    def record_execution(self, operation: str, execution_time: float, success: bool = True):
        """è®°å½•æ‰§è¡ŒæŒ‡æ ‡"""
        self.metrics['execution_times'].append({
            'operation': operation,
            'time': execution_time,
            'timestamp': datetime.now(),
            'success': success
        })
        
        if success:
            self.metrics['success_count'] += 1
        else:
            self.metrics['error_count'] += 1
    
    def record_tool_usage(self, tool_name: str):
        """è®°å½•å·¥å…·ä½¿ç”¨æƒ…å†µ"""
        if tool_name not in self.metrics['tool_usage']:
            self.metrics['tool_usage'][tool_name] = 0
        self.metrics['tool_usage'][tool_name] += 1
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–å­¦ä¹ æŒ‡æ ‡æ‘˜è¦"""
        total_operations = len(self.metrics['execution_times'])
        session_duration = datetime.now() - self.metrics['session_start']
        
        if self.metrics['execution_times']:
            avg_time = sum(op['time'] for op in self.metrics['execution_times']) / total_operations
            max_time = max(op['time'] for op in self.metrics['execution_times'])
            min_time = min(op['time'] for op in self.metrics['execution_times'])
        else:
            avg_time = max_time = min_time = 0
        
        return {
            'session_duration': session_duration.total_seconds(),
            'total_operations': total_operations,
            'success_rate': self.metrics['success_count'] / max(total_operations, 1) * 100,
            'average_execution_time': avg_time,
            'max_execution_time': max_time,
            'min_execution_time': min_time,
            'tool_usage_stats': self.metrics['tool_usage'],
            'most_used_tool': max(self.metrics['tool_usage'].items(), key=lambda x: x[1])[0] if self.metrics['tool_usage'] else None
        }
    
    def display_summary(self):
        """æ˜¾ç¤ºå­¦ä¹ æŒ‡æ ‡æ‘˜è¦"""
        summary = self.get_summary()
        
        print("ğŸ“Š å­¦ä¹ ä¼šè¯æŒ‡æ ‡æ‘˜è¦")
        print("=" * 40)
        print(f"ä¼šè¯æ—¶é•¿: {summary['session_duration']:.1f} ç§’")
        print(f"æ€»æ“ä½œæ•°: {summary['total_operations']}")
        print(f"æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        print(f"å¹³å‡æ‰§è¡Œæ—¶é—´: {summary['average_execution_time']:.3f} ç§’")
        print(f"æœ€é•¿æ‰§è¡Œæ—¶é—´: {summary['max_execution_time']:.3f} ç§’")
        print(f"æœ€çŸ­æ‰§è¡Œæ—¶é—´: {summary['min_execution_time']:.3f} ç§’")
        
        if summary['tool_usage_stats']:
            print(f"\\nğŸ› ï¸ å·¥å…·ä½¿ç”¨ç»Ÿè®¡:")
            for tool, count in sorted(summary['tool_usage_stats'].items(), key=lambda x: x[1], reverse=True):
                print(f"  {tool}: {count} æ¬¡")
            
            if summary['most_used_tool']:
                print(f"\\nğŸ† æœ€å¸¸ç”¨å·¥å…·: {summary['most_used_tool']}")

class ExampleCodeRunner:
    """ç¤ºä¾‹ä»£ç è¿è¡Œå™¨"""
    
    def __init__(self, enable_metrics: bool = True):
        self.enable_metrics = enable_metrics
        if enable_metrics:
            self.metrics = LearningMetrics()
    
    def run_example(self, example_name: str, code_func: Callable, *args, **kwargs):
        """è¿è¡Œç¤ºä¾‹ä»£ç """
        print(f"ğŸš€ è¿è¡Œç¤ºä¾‹: {example_name}")
        print("=" * 50)
        
        try:
            with CodeExecutionTimer(f"ç¤ºä¾‹ {example_name}") as timer:
                result = code_func(*args, **kwargs)
            
            if self.enable_metrics:
                self.metrics.record_execution(example_name, timer.get_execution_time(), True)
            
            print(f"\\nâœ… ç¤ºä¾‹ '{example_name}' æ‰§è¡ŒæˆåŠŸ")
            return result
            
        except Exception as e:
            if self.enable_metrics:
                execution_time = timer.get_execution_time() if 'timer' in locals() else 0
                self.metrics.record_execution(example_name, execution_time, False)
            
            print(f"\\nâŒ ç¤ºä¾‹ '{example_name}' æ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    def run_multiple_examples(self, examples: List[Dict[str, Any]]):
        """æ‰¹é‡è¿è¡Œå¤šä¸ªç¤ºä¾‹"""
        print(f"ğŸ¯ æ‰¹é‡è¿è¡Œ {len(examples)} ä¸ªç¤ºä¾‹")
        print("=" * 60)
        
        results = {}
        for i, example in enumerate(examples, 1):
            print(f"\\n[{i}/{len(examples)}] ", end="")
            
            try:
                result = self.run_example(
                    example['name'],
                    example['func'],
                    *example.get('args', []),
                    **example.get('kwargs', {})
                )
                results[example['name']] = {'success': True, 'result': result}
                
            except Exception as e:
                results[example['name']] = {'success': False, 'error': str(e)}
                print(f"ç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªç¤ºä¾‹...")
        
        # æ˜¾ç¤ºæ‰¹é‡æ‰§è¡Œæ‘˜è¦
        self._display_batch_summary(results)
        
        if self.enable_metrics:
            self.metrics.display_summary()
        
        return results
    
    def _display_batch_summary(self, results: Dict[str, Dict]):
        """æ˜¾ç¤ºæ‰¹é‡æ‰§è¡Œæ‘˜è¦"""
        success_count = sum(1 for r in results.values() if r['success'])
        total_count = len(results)
        
        print(f"\\nğŸ“Š æ‰¹é‡æ‰§è¡Œæ‘˜è¦")
        print("=" * 40)
        print(f"æ€»ç¤ºä¾‹æ•°: {total_count}")
        print(f"æˆåŠŸæ‰§è¡Œ: {success_count}")
        print(f"æ‰§è¡Œå¤±è´¥: {total_count - success_count}")
        print(f"æˆåŠŸç‡: {success_count / total_count * 100:.1f}%")
        
        # æ˜¾ç¤ºå¤±è´¥çš„ç¤ºä¾‹
        failed_examples = [name for name, result in results.items() if not result['success']]
        if failed_examples:
            print(f"\\nâŒ å¤±è´¥çš„ç¤ºä¾‹:")
            for example_name in failed_examples:
                error = results[example_name]['error']
                print(f"  â€¢ {example_name}: {error}")

class ConfigurationHelper:
    """é…ç½®è¾…åŠ©å·¥å…·"""
    
    @staticmethod
    def check_environment():
        """æ£€æŸ¥å­¦ä¹ ç¯å¢ƒé…ç½®"""
        print("ğŸ” æ£€æŸ¥å­¦ä¹ ç¯å¢ƒé…ç½®")
        print("=" * 40)
        
        # æ£€æŸ¥Pythonç‰ˆæœ¬
        python_version = sys.version_info
        print(f"Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
        
        if python_version >= (3, 9):
            print("âœ… Pythonç‰ˆæœ¬æ»¡è¶³è¦æ±‚ (>= 3.9)")
        else:
            print("âš ï¸ Pythonç‰ˆæœ¬å¯èƒ½è¿‡ä½ï¼Œå»ºè®®å‡çº§åˆ°3.9+")
        
        # æ£€æŸ¥å¿…éœ€çš„åŒ…
        required_packages = [
            'langchain',
            'langchain_openai',
            'openai',
            'pandas',
            'matplotlib',
            'jupyter',
            'python_dotenv'
        ]
        
        print(f"\\nğŸ“¦ æ£€æŸ¥å¿…éœ€åŒ…:")
        for package in required_packages:
            try:
                __import__(package)
                print(f"âœ… {package}: å·²å®‰è£…")
            except ImportError:
                print(f"âŒ {package}: æœªå®‰è£…")
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        print(f"\\nğŸ”‘ æ£€æŸ¥ç¯å¢ƒå˜é‡:")
        env_vars = ['OPENAI_API_KEY', 'ANTHROPIC_API_KEY']
        
        import os
        for var in env_vars:
            if os.getenv(var):
                print(f"âœ… {var}: å·²é…ç½®")
            else:
                print(f"âš ï¸ {var}: æœªé…ç½®")
    
    @staticmethod
    def generate_config_template() -> str:
        """ç”Ÿæˆé…ç½®æ–‡ä»¶æ¨¡æ¿"""
        template = """# LangChainå­¦ä¹ ç¯å¢ƒé…ç½®æ–‡ä»¶
# å¤åˆ¶æ­¤æ–‡ä»¶ä¸º .env å¹¶å¡«å…¥æ‚¨çš„APIå¯†é’¥

# OpenAI APIé…ç½®
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_ORG_ID=your_organization_id_here

# Anthropic APIé…ç½®  
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# å…¶ä»–é…ç½®
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=your_langsmith_api_key_here
LANGCHAIN_PROJECT=langchain-learning

# Jupyteré…ç½®
JUPYTER_ENABLE_LAB=true
JUPYTER_PORT=8888
"""
        return template
    
    @staticmethod
    def save_config_template(file_path: str = ".env.example"):
        """ä¿å­˜é…ç½®æ–‡ä»¶æ¨¡æ¿"""
        template = ConfigurationHelper.generate_config_template()
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(template)
            print(f"âœ… é…ç½®æ¨¡æ¿å·²ä¿å­˜åˆ°: {file_path}")
            print("ğŸ’¡ è¯·å¤åˆ¶æ­¤æ–‡ä»¶ä¸º .env å¹¶å¡«å…¥æ‚¨çš„APIå¯†é’¥")
        except Exception as e:
            print(f"âŒ ä¿å­˜é…ç½®æ¨¡æ¿å¤±è´¥: {e}")

class LearningPathGuide:
    """å­¦ä¹ è·¯å¾„æŒ‡å¯¼"""
    
    @staticmethod
    def get_learning_roadmap() -> Dict[str, List[str]]:
        """è·å–å®Œæ•´çš„å­¦ä¹ è·¯çº¿å›¾"""
        return {
            "åŸºç¡€æ¦‚å¿µ": [
                "01_langchain_introduction.ipynb - LangChainåŸºç¡€ä»‹ç»",
                "02_llm_basics.ipynb - å¤§è¯­è¨€æ¨¡å‹åŸºç¡€",
                "03_prompts_templates.ipynb - æç¤ºè¯å’Œæ¨¡æ¿"
            ],
            "æ ¸å¿ƒç»„ä»¶": [
                "01_chains_introduction.ipynb - é“¾çš„ä»‹ç»å’Œä½¿ç”¨",
                "02_agents_basics.ipynb - æ™ºèƒ½ä»£ç†åŸºç¡€",
                "03_memory_systems.ipynb - è®°å¿†ç³»ç»Ÿ"
            ],
            "é«˜çº§åº”ç”¨": [
                "01_rag_systems.ipynb - RAGæ£€ç´¢å¢å¼ºç”Ÿæˆ",
                "02_multi_agent.ipynb - å¤šä»£ç†ç³»ç»Ÿ",
                "03_evaluation.ipynb - è¯„ä¼°å’Œä¼˜åŒ–"
            ],
            "å®æˆ˜é¡¹ç›®": [
                "01_chatbot_project.ipynb - èŠå¤©æœºå™¨äººé¡¹ç›®",
                "02_qa_system.ipynb - é—®ç­”ç³»ç»Ÿé¡¹ç›®",
                "03_document_analysis.ipynb - æ–‡æ¡£åˆ†æé¡¹ç›®"
            ]
        }
    
    @staticmethod
    def recommend_next_steps(completed_notebooks: List[str]) -> List[str]:
        """æ ¹æ®å·²å®Œæˆçš„notebookæ¨èä¸‹ä¸€æ­¥å­¦ä¹ å†…å®¹"""
        roadmap = LearningPathGuide.get_learning_roadmap()
        
        # å±•å¹³æ‰€æœ‰è¯¾ç¨‹
        all_courses = []
        for category, courses in roadmap.items():
            for course in courses:
                notebook_name = course.split(" - ")[0]
                all_courses.append((category, notebook_name, course))
        
        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªåº”è¯¥å­¦ä¹ çš„è¯¾ç¨‹
        recommendations = []
        
        for category, notebook_name, full_description in all_courses:
            if notebook_name not in completed_notebooks:
                recommendations.append(full_description)
                if len(recommendations) >= 3:  # é™åˆ¶æ¨èæ•°é‡
                    break
        
        return recommendations
    
    @staticmethod
    def display_progress(completed_notebooks: List[str]):
        """æ˜¾ç¤ºå­¦ä¹ è¿›åº¦"""
        roadmap = LearningPathGuide.get_learning_roadmap()
        
        print("ğŸ“š å­¦ä¹ è¿›åº¦æ¦‚è§ˆ")
        print("=" * 50)
        
        total_courses = 0
        completed_courses = 0
        
        for category, courses in roadmap.items():
            print(f"\\nğŸ“– {category}:")
            category_completed = 0
            
            for course in courses:
                notebook_name = course.split(" - ")[0]
                total_courses += 1
                
                if notebook_name in completed_notebooks:
                    print(f"  âœ… {course}")
                    completed_courses += 1
                    category_completed += 1
                else:
                    print(f"  â­• {course}")
            
            completion_rate = category_completed / len(courses) * 100
            print(f"  ğŸ“Š åˆ†ç±»å®Œæˆåº¦: {completion_rate:.1f}%")
        
        overall_completion = completed_courses / total_courses * 100
        print(f"\\nğŸ¯ æ€»ä½“å®Œæˆåº¦: {overall_completion:.1f}% ({completed_courses}/{total_courses})")
        
        # æ¨èä¸‹ä¸€æ­¥
        recommendations = LearningPathGuide.recommend_next_steps(completed_notebooks)
        if recommendations:
            print(f"\\nğŸ“ˆ æ¨èä¸‹ä¸€æ­¥å­¦ä¹ :")
            for i, rec in enumerate(recommendations, 1):
                print(f"  {i}. {rec}")

# å…¨å±€å­¦ä¹ æŒ‡æ ‡å®ä¾‹
global_metrics = LearningMetrics()

# ä¾¿æ·å‡½æ•°
def quick_timer(description: str = ""):
    """å¿«é€Ÿåˆ›å»ºè®¡æ—¶å™¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    return CodeExecutionTimer(description)

def debug_chain(chain, verbose: bool = True):
    """å¿«é€Ÿè°ƒè¯•Chain"""
    return LangChainDebugger.inspect_chain_components(chain, verbose)

def debug_agent(agent_executor, verbose: bool = True):
    """å¿«é€Ÿè°ƒè¯•Agent"""
    return LangChainDebugger.inspect_agent_tools(agent_executor, verbose)

def check_env():
    """å¿«é€Ÿæ£€æŸ¥ç¯å¢ƒ"""
    ConfigurationHelper.check_environment()

def show_roadmap():
    """æ˜¾ç¤ºå­¦ä¹ è·¯çº¿å›¾"""
    roadmap = LearningPathGuide.get_learning_roadmap()
    
    print("ğŸ—ºï¸ LangChainå­¦ä¹ è·¯çº¿å›¾")
    print("=" * 50)
    
    for category, courses in roadmap.items():
        print(f"\\nğŸ“š {category}:")
        for i, course in enumerate(courses, 1):
            print(f"  {i}. {course}")

if __name__ == "__main__":
    # è¿è¡Œç¯å¢ƒæ£€æŸ¥
    print("ğŸ”§ LangChainå­¦ä¹ è¾…åŠ©å·¥å…·åˆå§‹åŒ–")
    print("=" * 50)
    
    check_env()
    print("\\n")
    show_roadmap()
    
    print("\\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("  â€¢ ä½¿ç”¨ quick_timer('æè¿°') æ¥è®¡æ—¶ä»£ç æ‰§è¡Œ")
    print("  â€¢ ä½¿ç”¨ debug_chain(chain) æ¥è°ƒè¯•é“¾")
    print("  â€¢ ä½¿ç”¨ debug_agent(agent) æ¥è°ƒè¯•ä»£ç†")
    print("  â€¢ ä½¿ç”¨ check_env() æ¥æ£€æŸ¥ç¯å¢ƒé…ç½®")
    print("  â€¢ ä½¿ç”¨ show_roadmap() æ¥æŸ¥çœ‹å­¦ä¹ è·¯çº¿å›¾")