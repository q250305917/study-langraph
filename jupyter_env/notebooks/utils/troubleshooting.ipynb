{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”§ LangChainå­¦ä¹ æ•…éšœæ’é™¤æŒ‡å—\n",
    "\n",
    "## ğŸ“‹ ç›®å½•\n",
    "1. [ç¯å¢ƒé…ç½®é—®é¢˜](#1-ç¯å¢ƒé…ç½®é—®é¢˜)\n",
    "2. [APIå¯†é’¥å’Œè®¤è¯é—®é¢˜](#2-apiå¯†é’¥å’Œè®¤è¯é—®é¢˜)\n",
    "3. [ä»£ç æ‰§è¡Œé—®é¢˜](#3-ä»£ç æ‰§è¡Œé—®é¢˜)\n",
    "4. [æ€§èƒ½å’Œä¼˜åŒ–é—®é¢˜](#4-æ€§èƒ½å’Œä¼˜åŒ–é—®é¢˜)\n",
    "5. [å­¦ä¹ æ–¹æ³•é—®é¢˜](#5-å­¦ä¹ æ–¹æ³•é—®é¢˜)\n",
    "6. [è¯Šæ–­å·¥å…·](#6-è¯Šæ–­å·¥å…·)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥è¯Šæ–­å·¥å…·\n",
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "print(\"ğŸ”§ LangChainæ•…éšœæ’é™¤å·¥å…·å·²åŠ è½½\")\n",
    "print(\"ä½¿ç”¨æœ¬æŒ‡å—å¯ä»¥è§£å†³å­¦ä¹ è¿‡ç¨‹ä¸­é‡åˆ°çš„å¸¸è§é—®é¢˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ğŸ› ï¸ ç¯å¢ƒé…ç½®é—®é¢˜\n",
    "\n",
    "### 1.1 Pythonç‰ˆæœ¬æ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_python_version():\n",
    "    \"\"\"æ£€æŸ¥Pythonç‰ˆæœ¬æ˜¯å¦ç¬¦åˆè¦æ±‚\"\"\"\n",
    "    print(\"ğŸ Pythonç‰ˆæœ¬æ£€æŸ¥\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    version = sys.version_info\n",
    "    print(f\"å½“å‰Pythonç‰ˆæœ¬: {version.major}.{version.minor}.{version.micro}\")\n",
    "    print(f\"å®Œæ•´ç‰ˆæœ¬ä¿¡æ¯: {sys.version}\")\n",
    "    print(f\"å¹³å°ä¿¡æ¯: {platform.platform()}\")\n",
    "    \n",
    "    if version >= (3, 9):\n",
    "        print(\"âœ… Pythonç‰ˆæœ¬ç¬¦åˆè¦æ±‚ (>= 3.9)\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"âš ï¸ Pythonç‰ˆæœ¬è¿‡ä½ï¼Œå»ºè®®å‡çº§åˆ°3.9æˆ–æ›´é«˜ç‰ˆæœ¬\")\n",
    "        print(\"\\nå‡çº§å»ºè®®:\")\n",
    "        print(\"â€¢ ä½¿ç”¨pyenv: pyenv install 3.11 && pyenv global 3.11\")\n",
    "        print(\"â€¢ ä½¿ç”¨conda: conda install python=3.11\")\n",
    "        print(\"â€¢ ä¸‹è½½å®˜æ–¹å®‰è£…åŒ…: https://www.python.org/downloads/\")\n",
    "        return False\n",
    "\n",
    "check_python_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 åŒ…ä¾èµ–æ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_package_dependencies():\n",
    "    \"\"\"æ£€æŸ¥å¿…éœ€çš„PythonåŒ…æ˜¯å¦å·²å®‰è£…\"\"\"\n",
    "    print(\"ğŸ“¦ åŒ…ä¾èµ–æ£€æŸ¥\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    required_packages = {\n",
    "        'langchain': 'æ ¸å¿ƒæ¡†æ¶',\n",
    "        'langchain_openai': 'OpenAIé›†æˆ',\n",
    "        'langchain_core': 'æ ¸å¿ƒç»„ä»¶',\n",
    "        'openai': 'OpenAIå®¢æˆ·ç«¯',\n",
    "        'pandas': 'æ•°æ®å¤„ç†',\n",
    "        'matplotlib': 'æ•°æ®å¯è§†åŒ–',\n",
    "        'numpy': 'æ•°å€¼è®¡ç®—',\n",
    "        'jupyter': 'Jupyterç¯å¢ƒ',\n",
    "        'python_dotenv': 'ç¯å¢ƒå˜é‡ç®¡ç†',\n",
    "        'pydantic': 'æ•°æ®éªŒè¯',\n",
    "        'requests': 'HTTPè¯·æ±‚'\n",
    "    }\n",
    "    \n",
    "    installed_packages = []\n",
    "    missing_packages = []\n",
    "    \n",
    "    for package, description in required_packages.items():\n",
    "        try:\n",
    "            module = importlib.import_module(package)\n",
    "            version = getattr(module, '__version__', 'Unknown')\n",
    "            print(f\"âœ… {package:<20} v{version:<10} - {description}\")\n",
    "            installed_packages.append(package)\n",
    "        except ImportError:\n",
    "            print(f\"âŒ {package:<20} {'æœªå®‰è£…':<10} - {description}\")\n",
    "            missing_packages.append(package)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ç»Ÿè®¡: {len(installed_packages)}/{len(required_packages)} å·²å®‰è£…\")\n",
    "    \n",
    "    if missing_packages:\n",
    "        print(f\"\\nğŸ”§ ä¿®å¤å‘½ä»¤:\")\n",
    "        install_cmd = f\"pip install {' '.join(missing_packages)}\"\n",
    "        print(f\"  {install_cmd}\")\n",
    "        \n",
    "        # æä¾›åˆ†ç»„å®‰è£…å‘½ä»¤\n",
    "        core_packages = [p for p in missing_packages if 'langchain' in p]\n",
    "        other_packages = [p for p in missing_packages if 'langchain' not in p]\n",
    "        \n",
    "        if core_packages:\n",
    "            print(f\"\\næ ¸å¿ƒåŒ…: pip install {' '.join(core_packages)}\")\n",
    "        if other_packages:\n",
    "            print(f\"è¾…åŠ©åŒ…: pip install {' '.join(other_packages)}\")\n",
    "    else:\n",
    "        print(\"\\nğŸ‰ æ‰€æœ‰å¿…éœ€åŒ…éƒ½å·²å®‰è£…ï¼\")\n",
    "    \n",
    "    return len(missing_packages) == 0\n",
    "\n",
    "check_package_dependencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 è™šæ‹Ÿç¯å¢ƒæ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_virtual_environment():\n",
    "    \"\"\"æ£€æŸ¥æ˜¯å¦åœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿è¡Œ\"\"\"\n",
    "    print(\"ğŸŒ è™šæ‹Ÿç¯å¢ƒæ£€æŸ¥\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ\n",
    "    in_venv = hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix)\n",
    "    \n",
    "    print(f\"Pythonè·¯å¾„: {sys.executable}\")\n",
    "    print(f\"ç³»ç»Ÿå‰ç¼€: {sys.prefix}\")\n",
    "    \n",
    "    if in_venv:\n",
    "        print(\"âœ… æ­£åœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿è¡Œ\")\n",
    "        \n",
    "        # å°è¯•è·å–è™šæ‹Ÿç¯å¢ƒåç§°\n",
    "        venv_name = os.path.basename(sys.prefix)\n",
    "        print(f\"ç¯å¢ƒåç§°: {venv_name}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âš ï¸ æœªæ£€æµ‹åˆ°è™šæ‹Ÿç¯å¢ƒ\")\n",
    "        print(\"\\nå»ºè®®åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ:\")\n",
    "        print(\"â€¢ ä½¿ç”¨venv: python -m venv langchain_env\")\n",
    "        print(\"â€¢ æ¿€æ´»ç¯å¢ƒ: source langchain_env/bin/activate (Linux/Mac)\")\n",
    "        print(\"â€¢ æ¿€æ´»ç¯å¢ƒ: langchain_env\\\\Scripts\\\\activate (Windows)\")\n",
    "        print(\"â€¢ ä½¿ç”¨conda: conda create -n langchain python=3.11\")\n",
    "        print(\"â€¢ æ¿€æ´»conda: conda activate langchain\")\n",
    "    \n",
    "    # æ£€æŸ¥VIRTUAL_ENVç¯å¢ƒå˜é‡\n",
    "    virtual_env = os.getenv('VIRTUAL_ENV')\n",
    "    if virtual_env:\n",
    "        print(f\"VIRTUAL_ENV: {virtual_env}\")\n",
    "    \n",
    "    return in_venv\n",
    "\n",
    "check_virtual_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ğŸ”‘ APIå¯†é’¥å’Œè®¤è¯é—®é¢˜\n",
    "\n",
    "### 2.1 ç¯å¢ƒå˜é‡æ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_api_keys():\n",
    "    \"\"\"æ£€æŸ¥APIå¯†é’¥é…ç½®\"\"\"\n",
    "    print(\"ğŸ”‘ APIå¯†é’¥æ£€æŸ¥\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # å°è¯•åŠ è½½.envæ–‡ä»¶\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "        print(\"âœ… .envæ–‡ä»¶å·²åŠ è½½\")\n",
    "    except ImportError:\n",
    "        print(\"âš ï¸ python-dotenvæœªå®‰è£…ï¼Œå¯èƒ½æ— æ³•åŠ è½½.envæ–‡ä»¶\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ åŠ è½½.envæ–‡ä»¶å¤±è´¥: {e}\")\n",
    "    \n",
    "    # æ£€æŸ¥å„ç§APIå¯†é’¥\n",
    "    api_keys = {\n",
    "        'OPENAI_API_KEY': 'OpenAI APIå¯†é’¥',\n",
    "        'ANTHROPIC_API_KEY': 'Anthropic Claude APIå¯†é’¥',\n",
    "        'LANGCHAIN_API_KEY': 'LangSmith APIå¯†é’¥',\n",
    "        'LANGCHAIN_TRACING_V2': 'LangSmithè¿½è¸ª',\n",
    "        'LANGCHAIN_PROJECT': 'LangSmithé¡¹ç›®å'\n",
    "    }\n",
    "    \n",
    "    configured_keys = []\n",
    "    missing_keys = []\n",
    "    \n",
    "    for key, description in api_keys.items():\n",
    "        value = os.getenv(key)\n",
    "        if value:\n",
    "            if 'API_KEY' in key:\n",
    "                # éšè—APIå¯†é’¥çš„å¤§éƒ¨åˆ†å†…å®¹\n",
    "                masked_value = value[:8] + '*' * (len(value) - 12) + value[-4:] if len(value) > 12 else '*' * len(value)\n",
    "                print(f\"âœ… {key:<25} - {description} ({masked_value})\")\n",
    "            else:\n",
    "                print(f\"âœ… {key:<25} - {description} ({value})\")\n",
    "            configured_keys.append(key)\n",
    "        else:\n",
    "            print(f\"âŒ {key:<25} - {description} (æœªé…ç½®)\")\n",
    "            missing_keys.append(key)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ç»Ÿè®¡: {len(configured_keys)}/{len(api_keys)} å·²é…ç½®\")\n",
    "    \n",
    "    if missing_keys:\n",
    "        print(f\"\\nğŸ”§ é…ç½®å»ºè®®:\")\n",
    "        print(\"1. åˆ›å»º.envæ–‡ä»¶åœ¨é¡¹ç›®æ ¹ç›®å½•\")\n",
    "        print(\"2. æ·»åŠ ä»¥ä¸‹å†…å®¹åˆ°.envæ–‡ä»¶:\")\n",
    "        for key in missing_keys:\n",
    "            print(f\"   {key}=your_{key.lower()}_here\")\n",
    "        print(\"3. é‡å¯Jupyterå†…æ ¸ä»¥åŠ è½½æ–°çš„ç¯å¢ƒå˜é‡\")\n",
    "    \n",
    "    return len(missing_keys) == 0\n",
    "\n",
    "check_api_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 APIè¿æ¥æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_openai_connection():\n",
    "    \"\"\"æµ‹è¯•OpenAI APIè¿æ¥\"\"\"\n",
    "    print(\"ğŸ”Œ OpenAI APIè¿æ¥æµ‹è¯•\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    if not api_key:\n",
    "        print(\"âŒ OPENAI_API_KEYæœªé…ç½®\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # å°è¯•å¯¼å…¥OpenAI\n",
    "        from openai import OpenAI\n",
    "        print(\"âœ… OpenAIåŒ…å¯¼å…¥æˆåŠŸ\")\n",
    "        \n",
    "        # åˆ›å»ºå®¢æˆ·ç«¯\n",
    "        client = OpenAI(api_key=api_key)\n",
    "        print(\"âœ… OpenAIå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ\")\n",
    "        \n",
    "        # æµ‹è¯•ç®€å•çš„APIè°ƒç”¨\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{\"role\": \"user\", \"content\": \"æµ‹è¯•è¿æ¥ï¼Œè¯·å›å¤'è¿æ¥æˆåŠŸ'\"}],\n",
    "                max_tokens=10\n",
    "            )\n",
    "            print(\"âœ… APIè°ƒç”¨æˆåŠŸ\")\n",
    "            print(f\"å“åº”: {response.choices[0].message.content}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as api_error:\n",
    "            print(f\"âŒ APIè°ƒç”¨å¤±è´¥: {api_error}\")\n",
    "            \n",
    "            # åˆ†æå¸¸è§é”™è¯¯\n",
    "            error_str = str(api_error).lower()\n",
    "            if \"invalid api key\" in error_str or \"unauthorized\" in error_str:\n",
    "                print(\"ğŸ’¡ å¯èƒ½çš„åŸå› : APIå¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ\")\n",
    "                print(\"   è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®ï¼Œæˆ–é‡æ–°ç”Ÿæˆ\")\n",
    "            elif \"insufficient quota\" in error_str or \"billing\" in error_str:\n",
    "                print(\"ğŸ’¡ å¯èƒ½çš„åŸå› : è´¦æˆ·ä½™é¢ä¸è¶³\")\n",
    "                print(\"   è§£å†³æ–¹æ¡ˆ: å……å€¼è´¦æˆ·æˆ–æ£€æŸ¥ä½¿ç”¨é™åˆ¶\")\n",
    "            elif \"rate limit\" in error_str:\n",
    "                print(\"ğŸ’¡ å¯èƒ½çš„åŸå› : è¯·æ±‚é¢‘ç‡è¿‡é«˜\")\n",
    "                print(\"   è§£å†³æ–¹æ¡ˆ: é™ä½è¯·æ±‚é¢‘ç‡æˆ–å‡çº§è´¦æˆ·\")\n",
    "            else:\n",
    "                print(\"ğŸ’¡ å»ºè®®: æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIå¯†é’¥\")\n",
    "            return False\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"âŒ OpenAIåŒ…æœªå®‰è£…\")\n",
    "        print(\"ğŸ”§ ä¿®å¤å‘½ä»¤: pip install openai\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {e}\")\n",
    "        return False\n",
    "\n",
    "def test_langchain_openai():\n",
    "    \"\"\"æµ‹è¯•LangChain OpenAIé›†æˆ\"\"\"\n",
    "    print(\"\\nğŸ”— LangChain OpenAIé›†æˆæµ‹è¯•\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    try:\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        print(\"âœ… LangChain OpenAIåŒ…å¯¼å…¥æˆåŠŸ\")\n",
    "        \n",
    "        # åˆ›å»ºLLMå®ä¾‹\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=0,\n",
    "            max_tokens=10\n",
    "        )\n",
    "        print(\"âœ… ChatOpenAIå®ä¾‹åˆ›å»ºæˆåŠŸ\")\n",
    "        \n",
    "        # æµ‹è¯•è°ƒç”¨\n",
    "        try:\n",
    "            response = llm.invoke(\"æµ‹è¯•LangChainè¿æ¥\")\n",
    "            print(\"âœ… LangChainè°ƒç”¨æˆåŠŸ\")\n",
    "            print(f\"å“åº”: {response.content}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ LangChainè°ƒç”¨å¤±è´¥: {e}\")\n",
    "            return False\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"âŒ LangChain OpenAIåŒ…æœªå®‰è£…\")\n",
    "        print(\"ğŸ”§ ä¿®å¤å‘½ä»¤: pip install langchain-openai\")\n",
    "        return False\n",
    "\n",
    "# è¿è¡Œè¿æ¥æµ‹è¯•\nopenai_ok = test_openai_connection()\nlangchain_ok = test_langchain_openai()\n",
    "\nprint(f\"\\nğŸ“‹ è¿æ¥æµ‹è¯•æ€»ç»“:\")\nprint(f\"  OpenAI API: {'âœ…' if openai_ok else 'âŒ'}\")\nprint(f\"  LangChainé›†æˆ: {'âœ…' if langchain_ok else 'âŒ'}\")\n\nif not (openai_ok or langchain_ok):\n    print(\"\\nâš ï¸ æ³¨æ„: APIè¿æ¥å¤±è´¥ï¼Œä½†æ‚¨ä»å¯ä»¥ï¼š\")\n    print(\"  â€¢ å­¦ä¹ ç†è®ºæ¦‚å¿µå’Œä»£ç ç»“æ„\")\n    print(\"  â€¢ ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼è¿è¡Œç¤ºä¾‹\")\n    print(\"  â€¢ é…ç½®å¥½APIåå†è¿›è¡Œå®é™…è°ƒç”¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ğŸ› ä»£ç æ‰§è¡Œé—®é¢˜\n",
    "\n",
    "### 3.1 å¸¸è§å¯¼å…¥é”™è¯¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose_import_errors():\n",
    "    \"\"\"è¯Šæ–­å¸¸è§çš„å¯¼å…¥é”™è¯¯\"\"\"\n",
    "    print(\"ğŸ“¥ å¯¼å…¥é”™è¯¯è¯Šæ–­\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # æµ‹è¯•å¸¸è§çš„å¯¼å…¥ç»„åˆ\n",
    "    import_tests = [\n",
    "        (\"langchain\", \"LangChainæ ¸å¿ƒåº“\"),\n",
    "        (\"langchain_core.prompts\", \"æ ¸å¿ƒæç¤ºè¯æ¨¡å—\"),\n",
    "        (\"langchain_core.output_parsers\", \"è¾“å‡ºè§£æå™¨\"),\n",
    "        (\"langchain_core.tools\", \"å·¥å…·ç³»ç»Ÿ\"),\n",
    "        (\"langchain_openai\", \"OpenAIé›†æˆ\"),\n",
    "        (\"langchain.agents\", \"Agentç³»ç»Ÿ\"),\n",
    "        (\"langchain.chains\", \"Chainç³»ç»Ÿ\"),\n",
    "        (\"langchain.memory\", \"è®°å¿†ç³»ç»Ÿ\")\n",
    "    ]\n",
    "    \n",
    "    success_count = 0\n",
    "    \n",
    "    for module_name, description in import_tests:\n",
    "        try:\n",
    "            importlib.import_module(module_name)\n",
    "            print(f\"âœ… {module_name:<30} - {description}\")\n",
    "            success_count += 1\n",
    "        except ImportError as e:\n",
    "            print(f\"âŒ {module_name:<30} - {description}\")\n",
    "            print(f\"   é”™è¯¯: {e}\")\n",
    "            \n",
    "            # æä¾›ä¿®å¤å»ºè®®\n",
    "            if \"langchain_openai\" in module_name:\n",
    "                print(f\"   ä¿®å¤: pip install langchain-openai\")\n",
    "            elif \"langchain\" in module_name:\n",
    "                print(f\"   ä¿®å¤: pip install langchain\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š å¯¼å…¥æˆåŠŸç‡: {success_count}/{len(import_tests)} ({success_count/len(import_tests)*100:.1f}%)\")\n",
    "    \n",
    "    if success_count < len(import_tests):\n",
    "        print(\"\\nğŸ”§ æ¨èçš„ä¿®å¤å‘½ä»¤:\")\n",
    "        print(\"pip install --upgrade langchain langchain-openai langchain-core\")\n",
    "    \n",
    "    return success_count == len(import_tests)\n",
    "\n",
    "diagnose_import_errors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 å†…å­˜å’Œæ€§èƒ½è¯Šæ–­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_system_resources():\n",
    "    \"\"\"æ£€æŸ¥ç³»ç»Ÿèµ„æºçŠ¶å†µ\"\"\"\n",
    "    print(\"ğŸ’» ç³»ç»Ÿèµ„æºæ£€æŸ¥\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    try:\n",
    "        import psutil\n",
    "        \n",
    "        # å†…å­˜ä¿¡æ¯\n",
    "        memory = psutil.virtual_memory()\n",
    "        print(f\"æ€»å†…å­˜: {memory.total / (1024**3):.1f} GB\")\n",
    "        print(f\"å¯ç”¨å†…å­˜: {memory.available / (1024**3):.1f} GB\")\n",
    "        print(f\"å†…å­˜ä½¿ç”¨ç‡: {memory.percent:.1f}%\")\n",
    "        \n",
    "        # CPUä¿¡æ¯\n",
    "        cpu_percent = psutil.cpu_percent(interval=1)\n",
    "        print(f\"CPUä½¿ç”¨ç‡: {cpu_percent:.1f}%\")\n",
    "        print(f\"CPUæ ¸å¿ƒæ•°: {psutil.cpu_count()}\")\n",
    "        \n",
    "        # ç£ç›˜ä¿¡æ¯\n",
    "        disk = psutil.disk_usage('.')\n",
    "        print(f\"ç£ç›˜ç©ºé—´: {disk.free / (1024**3):.1f} GB å¯ç”¨ / {disk.total / (1024**3):.1f} GB æ€»è®¡\")\n",
    "        \n",
    "        # æ€§èƒ½å»ºè®®\n",
    "        print(\"\\nğŸ’¡ æ€§èƒ½å»ºè®®:\")\n",
    "        if memory.percent > 80:\n",
    "            print(\"âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®å…³é—­å…¶ä»–ç¨‹åº\")\n",
    "        if memory.available / (1024**3) < 1:\n",
    "            print(\"âš ï¸ å¯ç”¨å†…å­˜ä¸è¶³1GBï¼Œå¯èƒ½å½±å“å¤§æ¨¡å‹è¿è¡Œ\")\n",
    "        if cpu_percent > 80:\n",
    "            print(\"âš ï¸ CPUä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®ç­‰å¾…å…¶ä»–ä»»åŠ¡å®Œæˆ\")\n",
    "        if disk.free / (1024**3) < 5:\n",
    "            print(\"âš ï¸ ç£ç›˜ç©ºé—´ä¸è¶³5GBï¼Œå»ºè®®æ¸…ç†ç©ºé—´\")\n",
    "        \n",
    "        if memory.percent <= 60 and cpu_percent <= 60:\n",
    "            print(\"âœ… ç³»ç»Ÿèµ„æºå……è¶³ï¼Œé€‚åˆè¿è¡ŒLangChainåº”ç”¨\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"âŒ psutilæœªå®‰è£…ï¼Œæ— æ³•è·å–è¯¦ç»†çš„ç³»ç»Ÿèµ„æºä¿¡æ¯\")\n",
    "        print(\"å®‰è£…å‘½ä»¤: pip install psutil\")\n",
    "        \n",
    "        # ä½¿ç”¨åŸºç¡€æ–¹æ³•è·å–ä¸€äº›ä¿¡æ¯\n",
    "        print(f\"\\nåŸºç¡€ä¿¡æ¯:\")\n",
    "        print(f\"å¹³å°: {platform.platform()}\")\n",
    "        print(f\"æ¶æ„: {platform.architecture()}\")\n",
    "        print(f\"å¤„ç†å™¨: {platform.processor() or 'Unknown'}\")\n",
    "\n",
    "check_system_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Jupyterç¯å¢ƒè¯Šæ–­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_jupyter_environment():\n",
    "    \"\"\"æ£€æŸ¥Jupyterç¯å¢ƒé…ç½®\"\"\"\n",
    "    print(\"ğŸ““ Jupyterç¯å¢ƒæ£€æŸ¥\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # æ£€æŸ¥Jupyterç›¸å…³åŒ…\n",
    "    jupyter_packages = ['jupyter', 'notebook', 'jupyterlab', 'ipykernel']\n",
    "    \n",
    "    for package in jupyter_packages:\n",
    "        try:\n",
    "            module = importlib.import_module(package)\n",
    "            version = getattr(module, '__version__', 'Unknown')\n",
    "            print(f\"âœ… {package:<15} v{version}\")\n",
    "        except ImportError:\n",
    "            print(f\"âš ï¸ {package:<15} æœªå®‰è£…\")\n",
    "    \n",
    "    # æ£€æŸ¥å†…æ ¸ä¿¡æ¯\n",
    "    print(f\"\\nğŸ”¬ å†…æ ¸ä¿¡æ¯:\")\n",
    "    print(f\"Pythonå¯æ‰§è¡Œæ–‡ä»¶: {sys.executable}\")\n",
    "    print(f\"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "    \n",
    "    # æ£€æŸ¥ç¯å¢ƒå˜é‡\n",
    "    jupyter_vars = ['JUPYTER_CONFIG_DIR', 'JUPYTER_DATA_DIR', 'JUPYTER_RUNTIME_DIR']\n",
    "    print(f\"\\nğŸ“ Jupyterç¯å¢ƒå˜é‡:\")\n",
    "    for var in jupyter_vars:\n",
    "        value = os.getenv(var)\n",
    "        if value:\n",
    "            print(f\"  {var}: {value}\")\n",
    "        else:\n",
    "            print(f\"  {var}: æœªè®¾ç½® (ä½¿ç”¨é»˜è®¤å€¼)\")\n",
    "    \n",
    "    # æ£€æŸ¥æ‰©å±•\n",
    "    try:\n",
    "        import IPython\n",
    "        print(f\"\\nğŸ§© IPythonç‰ˆæœ¬: {IPython.__version__}\")\n",
    "        \n",
    "        # è·å–é­”æ³•å‘½ä»¤\n",
    "        from IPython import get_ipython\n",
    "        ip = get_ipython()\n",
    "        if ip:\n",
    "            magic_commands = list(ip.magics_manager.magics['line'].keys())\n",
    "            print(f\"å¯ç”¨é­”æ³•å‘½ä»¤æ•°é‡: {len(magic_commands)}\")\n",
    "            print(f\"å¸¸ç”¨å‘½ä»¤: %time, %timeit, %matplotlib, %load_ext\")\n",
    "    except:\n",
    "        print(\"âš ï¸ æ— æ³•è·å–IPythonä¿¡æ¯\")\n",
    "    \n",
    "    # æä¾›æ•…éšœæ’é™¤å»ºè®®\n",
    "    print(f\"\\nğŸ”§ Jupyteræ•…éšœæ’é™¤:\")\n",
    "    print(\"â€¢ å†…æ ¸å´©æºƒ: Kernel â†’ Restart & Clear Output\")\n",
    "    print(\"â€¢ å¯¼å…¥é”™è¯¯: ç¡®ä¿åœ¨æ­£ç¡®çš„è™šæ‹Ÿç¯å¢ƒä¸­\")\n",
    "    print(\"â€¢ æ…¢å“åº”: æ£€æŸ¥ç³»ç»Ÿèµ„æºï¼Œé‡å¯å†…æ ¸\")\n",
    "    print(\"â€¢ æ‰©å±•é—®é¢˜: jupyter lab clean && jupyter lab build\")\n",
    "\n",
    "check_jupyter_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. âš¡ æ€§èƒ½å’Œä¼˜åŒ–é—®é¢˜\n",
    "\n",
    "### 4.1 APIè°ƒç”¨ä¼˜åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_api_performance():\n",
    "    \"\"\"åˆ†æAPIè°ƒç”¨æ€§èƒ½\"\"\"\n",
    "    print(\"âš¡ APIæ€§èƒ½åˆ†æ\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # æ€§èƒ½ä¼˜åŒ–å»ºè®®\n",
    "    optimization_tips = {\n",
    "        \"æ¨¡å‹é€‰æ‹©\": [\n",
    "            \"gpt-3.5-turbo: å¿«é€Ÿã€ä¾¿å®œï¼Œé€‚åˆå¤§å¤šæ•°ä»»åŠ¡\",\n",
    "            \"gpt-4: è´¨é‡é«˜ä½†è¾ƒæ…¢è¾ƒè´µï¼Œé€‚åˆå¤æ‚ä»»åŠ¡\",\n",
    "            \"gpt-4-turbo: å¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦\"\n",
    "        ],\n",
    "        \"å‚æ•°ä¼˜åŒ–\": [\n",
    "            \"temperature: 0-0.3 æé«˜ä¸€è‡´æ€§ï¼Œ0.7-1.0 å¢åŠ åˆ›é€ æ€§\",\n",
    "            \"max_tokens: é™åˆ¶å“åº”é•¿åº¦ä»¥èŠ‚çœæˆæœ¬\",\n",
    "            \"stream: å¯ç”¨æµå¼å“åº”æ”¹å–„ç”¨æˆ·ä½“éªŒ\"\n",
    "        ],\n",
    "        \"æç¤ºè¯ä¼˜åŒ–\": [\n",
    "            \"æ¸…æ™°ç®€æ´: é¿å…å†—ä½™ä¿¡æ¯\",\n",
    "            \"ç»“æ„åŒ–: ä½¿ç”¨æ˜ç¡®çš„æŒ‡ä»¤æ ¼å¼\",\n",
    "            \"ç¤ºä¾‹é©±åŠ¨: æä¾›few-shot examples\"\n",
    "        ],\n",
    "        \"ç¼“å­˜ç­–ç•¥\": [\n",
    "            \"ç›¸åŒæŸ¥è¯¢ç¼“å­˜ç»“æœ\",\n",
    "            \"ä½¿ç”¨æœ¬åœ°ç¼“å­˜å‡å°‘APIè°ƒç”¨\",\n",
    "            \"æ‰¹é‡å¤„ç†ç±»ä¼¼è¯·æ±‚\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for category, tips in optimization_tips.items():\n",
    "        print(f\"\\nğŸ¯ {category}:\")\n",
    "        for tip in tips:\n",
    "            print(f\"  â€¢ {tip}\")\n",
    "    \n",
    "    # æˆæœ¬ä¼°ç®—å·¥å…·\n",
    "    print(f\"\\nğŸ’° æˆæœ¬ä¼°ç®— (GPT-3.5-turbo):\")\n",
    "    print(f\"  è¾“å…¥: $0.0015 / 1K tokens\")\n",
    "    print(f\"  è¾“å‡º: $0.002 / 1K tokens\")\n",
    "    print(f\"  ç¤ºä¾‹: 1000å­—å¯¹è¯çº¦0.5ç¾å…ƒ\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š æ€§èƒ½åŸºå‡†:\")\n",
    "    print(f\"  gpt-3.5-turbo: ~2-5ç§’å“åº”æ—¶é—´\")\n",
    "    print(f\"  gpt-4: ~10-30ç§’å“åº”æ—¶é—´\")\n",
    "    print(f\"  æµå¼å“åº”: é¦–å­—èŠ‚<1ç§’\")\n",
    "\n",
    "analyze_api_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 å†…å­˜ä½¿ç”¨ä¼˜åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_optimization_guide():\n",
    "    \"\"\"å†…å­˜ä¼˜åŒ–æŒ‡å¯¼\"\"\"\n",
    "    print(\"ğŸ§  å†…å­˜ä½¿ç”¨ä¼˜åŒ–\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # è·å–å½“å‰å†…å­˜ä½¿ç”¨\n",
    "    try:\n",
    "        import psutil\n",
    "        process = psutil.Process()\n",
    "        memory_info = process.memory_info()\n",
    "        print(f\"å½“å‰è¿›ç¨‹å†…å­˜ä½¿ç”¨: {memory_info.rss / 1024 / 1024:.1f} MB\")\n",
    "    except:\n",
    "        print(\"æ— æ³•è·å–å†…å­˜ä½¿ç”¨ä¿¡æ¯\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ å†…å­˜ä¼˜åŒ–ç­–ç•¥:\")\n",
    "    \n",
    "    strategies = {\n",
    "        \"æ•°æ®å¤„ç†\": [\n",
    "            \"ä½¿ç”¨ç”Ÿæˆå™¨è€Œä¸æ˜¯åˆ—è¡¨å­˜å‚¨å¤§é‡æ•°æ®\",\n",
    "            \"åŠæ—¶åˆ é™¤ä¸éœ€è¦çš„å˜é‡\",\n",
    "            \"åˆ†æ‰¹å¤„ç†å¤§å‹æ•°æ®é›†\"\n",
    "        ],\n",
    "        \"æ¨¡å‹ä½¿ç”¨\": [\n",
    "            \"é¿å…åŒæ—¶åŠ è½½å¤šä¸ªå¤§æ¨¡å‹\",\n",
    "            \"ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹è¿›è¡Œå¼€å‘æµ‹è¯•\",\n",
    "            \"åŠæ—¶é‡Šæ”¾ä¸ç”¨çš„æ¨¡å‹å®ä¾‹\"\n",
    "        ],\n",
    "        \"ç¼“å­˜ç®¡ç†\": [\n",
    "            \"é™åˆ¶ç¼“å­˜å¤§å°\",\n",
    "            \"ä½¿ç”¨LRUç¼“å­˜ç­–ç•¥\",\n",
    "            \"å®šæœŸæ¸…ç†è¿‡æœŸç¼“å­˜\"\n",
    "        ],\n",
    "        \"Jupyterä¼˜åŒ–\": [\n",
    "            \"å®šæœŸé‡å¯å†…æ ¸æ¸…ç†å†…å­˜\",\n",
    "            \"é¿å…åœ¨å•ä¸ªcellä¸­å¤„ç†è¿‡å¤šæ•°æ®\",\n",
    "            \"ä½¿ç”¨%reseté­”æ³•å‘½ä»¤æ¸…ç†å˜é‡\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for category, tips in strategies.items():\n",
    "        print(f\"\\nğŸ”§ {category}:\")\n",
    "        for tip in tips:\n",
    "            print(f\"  â€¢ {tip}\")\n",
    "    \n",
    "    # å†…å­˜ç›‘æ§ä»£ç ç¤ºä¾‹\n",
    "    print(f\"\\nğŸ“ å†…å­˜ç›‘æ§ç¤ºä¾‹ä»£ç :\")\n",
    "    monitoring_code = \"\"\"\n",
    "# ç›‘æ§å†…å­˜ä½¿ç”¨\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "def check_memory():\n",
    "    process = psutil.Process()\n",
    "    return process.memory_info().rss / 1024 / 1024\n",
    "\n",
    "# ä½¿ç”¨å‰åå¯¹æ¯”\n",
    "before = check_memory()\n",
    "# ... ä½ çš„ä»£ç  ...\n",
    "after = check_memory()\n",
    "print(f\"å†…å­˜å˜åŒ–: {after - before:.1f} MB\")\n",
    "\n",
    "# æ‰‹åŠ¨åƒåœ¾å›æ”¶\n",
    "gc.collect()\n",
    "\"\"\"\n",
    "    print(monitoring_code)\n",
    "\n",
    "memory_optimization_guide()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ğŸ“š å­¦ä¹ æ–¹æ³•é—®é¢˜\n",
    "\n",
    "### 5.1 å­¦ä¹ è¿›åº¦è¯Šæ–­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_progress_analysis():\n",
    "    \"\"\"åˆ†æå­¦ä¹ è¿›åº¦å’Œæä¾›å»ºè®®\"\"\"\n",
    "    print(\"ğŸ“ˆ å­¦ä¹ è¿›åº¦åˆ†æ\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # å¯¼å…¥è¿›åº¦è¿½è¸ªå™¨\n",
    "    try:\n",
    "        from progress_tracker import ProgressTracker\n",
    "        tracker = ProgressTracker()\n",
    "        progress = tracker.get_progress_summary()\n",
    "        \n",
    "        print(f\"âœ… è¿›åº¦æ•°æ®åŠ è½½æˆåŠŸ\")\n",
    "        print(f\"æ€»å­¦ä¹ æ—¶é—´: {progress['total_time_hours']:.1f} å°æ—¶\")\n",
    "        print(f\"å®Œæˆè¯¾ç¨‹æ•°: {progress['completed_lessons']}\")\n",
    "        print(f\"å®Œæˆç»ƒä¹ æ•°: {progress['completed_exercises']}\")\n",
    "        print(f\"å¹³å‡åˆ†æ•°: {progress['average_score']:.1f}\")\n",
    "        \n",
    "        # åˆ†æå­¦ä¹ æ¨¡å¼\n",
    "        print(f\"\\nğŸ” å­¦ä¹ æ¨¡å¼åˆ†æ:\")\n",
    "        \n",
    "        hours = progress['total_time_hours']\n",
    "        lessons = progress['completed_lessons']\n",
    "        exercises = progress['completed_exercises']\n",
    "        score = progress['average_score']\n",
    "        \n",
    "        # å­¦ä¹ é€Ÿåº¦åˆ†æ\n",
    "        if hours > 0 and lessons > 0:\n",
    "            hours_per_lesson = hours / lessons\n",
    "            print(f\"  å¹³å‡æ¯è¯¾ç¨‹å­¦ä¹ æ—¶é—´: {hours_per_lesson:.1f} å°æ—¶\")\n",
    "            \n",
    "            if hours_per_lesson < 0.5:\n",
    "                print(f\"  ğŸš€ å­¦ä¹ é€Ÿåº¦: è¾ƒå¿« - å»ºè®®æ·±å…¥ç»ƒä¹ \")\n",
    "            elif hours_per_lesson < 1.5:\n",
    "                print(f\"  âš¡ å­¦ä¹ é€Ÿåº¦: é€‚ä¸­ - ä¿æŒå½“å‰èŠ‚å¥\")\n",
    "            else:\n",
    "                print(f\"  ğŸŒ å­¦ä¹ é€Ÿåº¦: è¾ƒæ…¢ - å»ºè®®å¤ä¹ åŸºç¡€æ¦‚å¿µ\")\n",
    "        \n",
    "        # ç»ƒä¹ å®Œæˆåº¦åˆ†æ\n",
    "        if lessons > 0:\n",
    "            exercises_per_lesson = exercises / lessons if lessons > 0 else 0\n",
    "            print(f\"  å¹³å‡æ¯è¯¾ç¨‹ç»ƒä¹ æ•°: {exercises_per_lesson:.1f}\")\n",
    "            \n",
    "            if exercises_per_lesson < 2:\n",
    "                print(f\"  ğŸ“ ç»ƒä¹ åº¦: åä½ - å»ºè®®å¤šåšç»ƒä¹ \")\n",
    "            elif exercises_per_lesson < 4:\n",
    "                print(f\"  ğŸ“š ç»ƒä¹ åº¦: é€‚ä¸­ - ç»§ç»­ä¿æŒ\")\n",
    "            else:\n",
    "                print(f\"  ğŸ† ç»ƒä¹ åº¦: å¾ˆé«˜ - å­¦ä¹ æ€åº¦ä¼˜ç§€\")\n",
    "        \n",
    "        # æˆç»©åˆ†æ\n",
    "        if score >= 90:\n",
    "            print(f\"  ğŸ¯ æŒæ¡ç¨‹åº¦: ä¼˜ç§€ - å¯ä»¥å°è¯•é«˜çº§å†…å®¹\")\n",
    "        elif score >= 75:\n",
    "            print(f\"  ğŸ‘ æŒæ¡ç¨‹åº¦: è‰¯å¥½ - ç»§ç»­å½“å‰è¿›åº¦\")\n",
    "        elif score >= 60:\n",
    "            print(f\"  ğŸ“– æŒæ¡ç¨‹åº¦: ä¸€èˆ¬ - å»ºè®®é‡ç‚¹å¤ä¹ \")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ æŒæ¡ç¨‹åº¦: éœ€æé«˜ - ä»åŸºç¡€å¼€å§‹å·©å›º\")\n",
    "    \n",
    "    except:\n",
    "        print(\"âš ï¸ æ— æ³•åŠ è½½è¿›åº¦æ•°æ®ï¼Œæä¾›ä¸€èˆ¬æ€§å»ºè®®\")\n",
    "    \n",
    "    # é€šç”¨å­¦ä¹ å»ºè®®\n",
    "    print(f\"\\nğŸ’¡ å­¦ä¹ æ–¹æ³•å»ºè®®:\")\n",
    "    \n",
    "    learning_tips = [\n",
    "        \"ğŸ“š ç†è®ºä¸å®è·µç»“åˆ: ç†è§£æ¦‚å¿µåç«‹å³åŠ¨æ‰‹ç»ƒä¹ \",\n",
    "        \"ğŸ”„ å®šæœŸå¤ä¹ : æ¯å‘¨å›é¡¾ä¹‹å‰å­¦è¿‡çš„å†…å®¹\",\n",
    "        \"ğŸ¯ é¡¹ç›®é©±åŠ¨: é€šè¿‡å®é™…é¡¹ç›®åº”ç”¨æ‰€å­¦çŸ¥è¯†\",\n",
    "        \"ğŸ‘¥ ç¤¾åŒºå‚ä¸: å‚ä¸è®¨è®ºï¼Œåˆ†äº«å­¦ä¹ å¿ƒå¾—\",\n",
    "        \"ğŸ“ ç¬”è®°è®°å½•: è®°å½•é‡è¦æ¦‚å¿µå’Œä»£ç ç‰‡æ®µ\",\n",
    "        \"ğŸ› é”™è¯¯åˆ†æ: è®¤çœŸåˆ†ææ¯ä¸ªé”™è¯¯çš„åŸå› \",\n",
    "        \"â° æ—¶é—´ç®¡ç†: æ¯æ¬¡å­¦ä¹ 30-60åˆ†é’Ÿï¼Œä¿æŒä¸“æ³¨\"\n",
    "    ]\n",
    "    \n",
    "    for tip in learning_tips:\n",
    "        print(f\"  â€¢ {tip}\")\n",
    "\n",
    "learning_progress_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 å¸¸è§å­¦ä¹ å›°éš¾åŠè§£å†³æ–¹æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_learning_challenges():\n",
    "    \"\"\"åˆ†æå¸¸è§å­¦ä¹ å›°éš¾å¹¶æä¾›è§£å†³æ–¹æ¡ˆ\"\"\"\n",
    "    print(\"ğŸ¤” å¸¸è§å­¦ä¹ å›°éš¾åˆ†æ\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    challenges = {\n",
    "        \"æ¦‚å¿µç†è§£å›°éš¾\": {\n",
    "            \"ç—‡çŠ¶\": [\"ç†è®ºçœ‹ä¸æ‡‚\", \"æ¦‚å¿µæ··æ·†\", \"ä¸çŸ¥é“æ€ä¹ˆåº”ç”¨\"],\n",
    "            \"åŸå› \": [\"åŸºç¡€çŸ¥è¯†ä¸è¶³\", \"å­¦ä¹ é¡ºåºé”™è¯¯\", \"ç¼ºå°‘å®è·µ\"],\n",
    "            \"è§£å†³æ–¹æ¡ˆ\": [\n",
    "                \"é‡æ–°å­¦ä¹ PythonåŸºç¡€\",\n",
    "                \"æŒ‰ç…§æ¨èé¡ºåºå­¦ä¹ \",\n",
    "                \"å¤šçœ‹ç¤ºä¾‹ä»£ç \",\n",
    "                \"ç”»æ¦‚å¿µå›¾å¸®åŠ©ç†è§£\"\n",
    "            ]\n",
    "        },\n",
    "        \"ä»£ç å®è·µå›°éš¾\": {\n",
    "            \"ç—‡çŠ¶\": [\"ä»£ç æ€»æ˜¯å‡ºé”™\", \"ä¸ä¼šä¿®æ”¹ç¤ºä¾‹\", \"æ— æ³•ç‹¬ç«‹ç¼–å†™\"],\n",
    "            \"åŸå› \": [\"ç¼–ç¨‹åŸºç¡€è–„å¼±\", \"è°ƒè¯•èƒ½åŠ›ä¸è¶³\", \"ç»ƒä¹ ä¸å¤Ÿ\"],\n",
    "            \"è§£å†³æ–¹æ¡ˆ\": [\n",
    "                \"åŠ å¼ºPythonç¼–ç¨‹ç»ƒä¹ \",\n",
    "                \"å­¦ä¼šä½¿ç”¨è°ƒè¯•å·¥å…·\",\n",
    "                \"ä»ç®€å•ä¿®æ”¹å¼€å§‹\",\n",
    "                \"é€æ­¥å¢åŠ å¤æ‚åº¦\"\n",
    "            ]\n",
    "        },\n",
    "        \"ç¯å¢ƒé…ç½®å›°éš¾\": {\n",
    "            \"ç—‡çŠ¶\": [\"åŒ…å®‰è£…å¤±è´¥\", \"APIè°ƒç”¨ä¸æˆåŠŸ\", \"ç¯å¢ƒå†²çª\"],\n",
    "            \"åŸå› \": [\"ç½‘ç»œé—®é¢˜\", \"æƒé™ä¸è¶³\", \"ç‰ˆæœ¬å†²çª\"],\n",
    "            \"è§£å†³æ–¹æ¡ˆ\": [\n",
    "                \"ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ\",\n",
    "                \"æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯\",\n",
    "                \"ä½¿ç”¨å›½å†…é•œåƒæº\",\n",
    "                \"å¯»æ±‚æŠ€æœ¯æ”¯æŒ\"\n",
    "            ]\n",
    "        },\n",
    "        \"å­¦ä¹ åŠ¨åŠ›ä¸è¶³\": {\n",
    "            \"ç—‡çŠ¶\": [\"å®¹æ˜“æ”¾å¼ƒ\", \"è¿›åº¦ç¼“æ…¢\", \"ç¼ºä¹å…´è¶£\"],\n",
    "            \"åŸå› \": [\"ç›®æ ‡ä¸æ˜ç¡®\", \"æ²¡æœ‰æˆå°±æ„Ÿ\", \"å­¦ä¹ å­¤å•\"],\n",
    "            \"è§£å†³æ–¹æ¡ˆ\": [\n",
    "                \"è®¾å®šå…·ä½“çš„å­¦ä¹ ç›®æ ‡\",\n",
    "                \"åº†ç¥å°çš„è¿›æ­¥\",\n",
    "                \"æ‰¾å­¦ä¹ ä¼™ä¼´\",\n",
    "                \"å…³æ³¨å®é™…åº”ç”¨ä»·å€¼\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for challenge, details in challenges.items():\n",
    "        print(f\"\\nğŸ¯ {challenge}\")\n",
    "        print(f\"  ç—‡çŠ¶: {', '.join(details['ç—‡çŠ¶'])}\")\n",
    "        print(f\"  åŸå› : {', '.join(details['åŸå› '])}\")\n",
    "        print(f\"  è§£å†³æ–¹æ¡ˆ:\")\n",
    "        for solution in details['è§£å†³æ–¹æ¡ˆ']:\n",
    "            print(f\"    â€¢ {solution}\")\n",
    "    \n",
    "    # è‡ªæˆ‘è¯Šæ–­é—®å·\n",
    "    print(f\"\\nğŸ“‹ å­¦ä¹ å›°éš¾è‡ªæˆ‘è¯Šæ–­:\")\n",
    "    print(\"è¯·è¯šå®å›ç­”ä»¥ä¸‹é—®é¢˜ï¼ˆæ˜¯/å¦ï¼‰:\")\n",
    "    \n",
    "    questions = [\n",
    "        \"æˆ‘ç»å¸¸çœ‹ä¸æ‡‚ç†è®ºæ¦‚å¿µ\",\n",
    "        \"æˆ‘çš„ä»£ç ç»å¸¸å‡ºç°é”™è¯¯\",\n",
    "        \"æˆ‘å¾ˆéš¾é…ç½®å¼€å‘ç¯å¢ƒ\",\n",
    "        \"æˆ‘ç»å¸¸æƒ³è¦æ”¾å¼ƒå­¦ä¹ \",\n",
    "        \"æˆ‘ä¸çŸ¥é“å¦‚ä½•åº”ç”¨æ‰€å­¦çŸ¥è¯†\",\n",
    "        \"æˆ‘è§‰å¾—å­¦ä¹ è¿›åº¦å¤ªæ…¢\",\n",
    "        \"æˆ‘ç¼ºä¹å­¦ä¹ çš„åŠ¨åŠ›\"\n",
    "    ]\n",
    "    \n",
    "    for i, question in enumerate(questions, 1):\n",
    "        print(f\"  {i}. {question}\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ è¯Šæ–­è¯´æ˜:\")\n",
    "    print(f\"  â€¢ 1-2ä¸ª'æ˜¯': å­¦ä¹ çŠ¶æ€è‰¯å¥½\")\n",
    "    print(f\"  â€¢ 3-4ä¸ª'æ˜¯': éœ€è¦è°ƒæ•´å­¦ä¹ æ–¹æ³•\")\n",
    "    print(f\"  â€¢ 5+ä¸ª'æ˜¯': å»ºè®®å¯»æ±‚å¸®åŠ©å’ŒæŒ‡å¯¼\")\n",
    "\n",
    "common_learning_challenges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ğŸ” è¯Šæ–­å·¥å…·\n",
    "\n",
    "### 6.1 ä¸€é”®ç¯å¢ƒè¯Šæ–­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_diagnosis():\n",
    "    \"\"\"ç»¼åˆç¯å¢ƒè¯Šæ–­\"\"\"\n",
    "    print(\"ğŸ” å¼€å§‹ç»¼åˆç¯å¢ƒè¯Šæ–­\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    diagnosis_results = {}\n",
    "    \n",
    "    # 1. Pythonç‰ˆæœ¬æ£€æŸ¥\n",
    "    print(\"\\n1ï¸âƒ£ Pythonç‰ˆæœ¬æ£€æŸ¥\")\n",
    "    diagnosis_results['python'] = check_python_version()\n",
    "    \n",
    "    # 2. åŒ…ä¾èµ–æ£€æŸ¥\n",
    "    print(\"\\n2ï¸âƒ£ åŒ…ä¾èµ–æ£€æŸ¥\")\n",
    "    diagnosis_results['packages'] = check_package_dependencies()\n",
    "    \n",
    "    # 3. è™šæ‹Ÿç¯å¢ƒæ£€æŸ¥\n",
    "    print(\"\\n3ï¸âƒ£ è™šæ‹Ÿç¯å¢ƒæ£€æŸ¥\")\n",
    "    diagnosis_results['venv'] = check_virtual_environment()\n",
    "    \n",
    "    # 4. APIå¯†é’¥æ£€æŸ¥\n",
    "    print(\"\\n4ï¸âƒ£ APIå¯†é’¥æ£€æŸ¥\")\n",
    "    diagnosis_results['api_keys'] = check_api_keys()\n",
    "    \n",
    "    # 5. ç³»ç»Ÿèµ„æºæ£€æŸ¥\n",
    "    print(\"\\n5ï¸âƒ£ ç³»ç»Ÿèµ„æºæ£€æŸ¥\")\n",
    "    check_system_resources()\n",
    "    diagnosis_results['resources'] = True  # å‡è®¾é€šè¿‡\n",
    "    \n",
    "    # 6. Jupyterç¯å¢ƒæ£€æŸ¥\n",
    "    print(\"\\n6ï¸âƒ£ Jupyterç¯å¢ƒæ£€æŸ¥\")\n",
    "    check_jupyter_environment()\n",
    "    diagnosis_results['jupyter'] = True  # å‡è®¾é€šè¿‡\n",
    "    \n",
    "    # ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“Š è¯Šæ–­æŠ¥å‘Šæ€»ç»“\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    passed_count = sum(diagnosis_results.values())\n",
    "    total_count = len(diagnosis_results)\n",
    "    \n",
    "    for check, result in diagnosis_results.items():\n",
    "        status = \"âœ… é€šè¿‡\" if result else \"âŒ å¤±è´¥\"\n",
    "        print(f\"{check:<15}: {status}\")\n",
    "    \n",
    "    print(f\"\\næ€»ä½“çŠ¶æ€: {passed_count}/{total_count} é¡¹æ£€æŸ¥é€šè¿‡\")\n",
    "    \n",
    "    # ç”Ÿæˆå»ºè®®\n",
    "    if passed_count == total_count:\n",
    "        print(\"\\nğŸ‰ æ­å–œï¼æ‚¨çš„ç¯å¢ƒé…ç½®å®Œç¾ï¼\")\n",
    "        print(\"å¯ä»¥å¼€å§‹æ„‰å¿«çš„LangChainå­¦ä¹ ä¹‹æ—…äº†ï¼\")\n",
    "    elif passed_count >= total_count * 0.7:\n",
    "        print(\"\\nğŸ‘ æ‚¨çš„ç¯å¢ƒåŸºæœ¬é…ç½®æ­£ç¡®ï¼\")\n",
    "        print(\"ä¿®å¤å‰©ä½™é—®é¢˜åå³å¯è·å¾—æœ€ä½³å­¦ä¹ ä½“éªŒã€‚\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ æ‚¨çš„ç¯å¢ƒéœ€è¦ä¸€äº›ä¿®å¤\")\n",
    "        print(\"å»ºè®®æŒ‰ç…§ä¸Šè¿°æ£€æŸ¥ç»“æœé€é¡¹ä¿®å¤é—®é¢˜ã€‚\")\n",
    "    \n",
    "    # ç”Ÿæˆä¿®å¤è„šæœ¬\n",
    "    print(f\"\\nğŸ”§ å¿«é€Ÿä¿®å¤è„šæœ¬:\")\n",
    "    fix_commands = []\n",
    "    \n",
    "    if not diagnosis_results.get('packages', True):\n",
    "        fix_commands.append(\"pip install langchain langchain-openai pandas matplotlib jupyter python-dotenv\")\n",
    "    \n",
    "    if not diagnosis_results.get('api_keys', True):\n",
    "        fix_commands.append(\"# åˆ›å»º.envæ–‡ä»¶å¹¶æ·»åŠ APIå¯†é’¥\")\n",
    "    \n",
    "    if fix_commands:\n",
    "        for cmd in fix_commands:\n",
    "            print(f\"  {cmd}\")\n",
    "    else:\n",
    "        print(\"  æ— éœ€ä¿®å¤å‘½ä»¤ï¼\")\n",
    "    \n",
    "    return diagnosis_results\n",
    "\n",
    "# è¿è¡Œç»¼åˆè¯Šæ–­\ndiagnosis = comprehensive_diagnosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_diagnosis_report():\n",
    "    \"\"\"ç”Ÿæˆè¯¦ç»†çš„è¯Šæ–­æŠ¥å‘Š\"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    print(\"ğŸ“„ ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # æ”¶é›†ç³»ç»Ÿä¿¡æ¯\n",
    "    report_data = {\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'platform': platform.platform(),\n",
    "        'python_version': f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\",\n",
    "        'python_executable': sys.executable,\n",
    "        'working_directory': os.getcwd(),\n",
    "        'environment_variables': {\n",
    "            'OPENAI_API_KEY': 'å·²é…ç½®' if os.getenv('OPENAI_API_KEY') else 'æœªé…ç½®',\n",
    "            'VIRTUAL_ENV': os.getenv('VIRTUAL_ENV', 'æœªä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ')\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # ç”ŸæˆæŠ¥å‘Šå†…å®¹\n",
    "    report_content = f\"\"\"\n",
    "# LangChainå­¦ä¹ ç¯å¢ƒè¯Šæ–­æŠ¥å‘Š\n",
    "\n",
    "ç”Ÿæˆæ—¶é—´: {report_data['timestamp']}\n",
    "\n",
    "## ç³»ç»Ÿä¿¡æ¯\n",
    "- æ“ä½œç³»ç»Ÿ: {report_data['platform']}\n",
    "- Pythonç‰ˆæœ¬: {report_data['python_version']}\n",
    "- Pythonè·¯å¾„: {report_data['python_executable']}\n",
    "- å·¥ä½œç›®å½•: {report_data['working_directory']}\n",
    "\n",
    "## ç¯å¢ƒé…ç½®\n",
    "- OpenAI APIå¯†é’¥: {report_data['environment_variables']['OPENAI_API_KEY']}\n",
    "- è™šæ‹Ÿç¯å¢ƒ: {report_data['environment_variables']['VIRTUAL_ENV']}\n",
    "\n",
    "## å»ºè®®çš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨\n",
    "1. å¦‚æœ‰é…ç½®é—®é¢˜ï¼Œè¯·æŒ‰ç…§æ•…éšœæ’é™¤æŒ‡å—ä¿®å¤\n",
    "2. ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åŒ…éƒ½å·²å®‰è£…\n",
    "3. é…ç½®APIå¯†é’¥ä»¥è·å¾—å®Œæ•´åŠŸèƒ½\n",
    "4. å¼€å§‹ç³»ç»Ÿæ€§çš„LangChainå­¦ä¹ \n",
    "\n",
    "## å­¦ä¹ èµ„æº\n",
    "- ç»¼åˆå­¦ä¹ æŒ‡å—: comprehensive_guide.ipynb\n",
    "- è¿›åº¦è¿½è¸ª: progress_tracker.py\n",
    "- å­¦ä¹ è¾…åŠ©å·¥å…·: learning_helpers.py\n",
    "\n",
    "---\n",
    "æŠ¥å‘Šç”±LangChainå­¦ä¹ ç¯å¢ƒè‡ªåŠ¨ç”Ÿæˆ\n",
    "\"\"\"\n",
    "    \n",
    "    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶\n",
    "    report_filename = f\"diagnosis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md\"\n",
    "    \n",
    "    try:\n",
    "        with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(report_content)\n",
    "        print(f\"âœ… è¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜: {report_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºæŠ¥å‘Šæ‘˜è¦\n",
    "    print(f\"\\nğŸ“‹ æŠ¥å‘Šæ‘˜è¦:\")\n",
    "    print(f\"  æ—¶é—´: {report_data['timestamp']}\")\n",
    "    print(f\"  å¹³å°: {report_data['platform']}\")\n",
    "    print(f\"  Python: {report_data['python_version']}\")\n",
    "    \n",
    "    return report_content\n",
    "\n",
    "# ç”ŸæˆæŠ¥å‘Š\nreport = generate_diagnosis_report()\n\nprint(\"\\nğŸ‰ æ•…éšœæ’é™¤æŒ‡å—ä½¿ç”¨å®Œæˆï¼\")\nprint(\"å¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè¯·ï¼š\")\nprint(\"  1. æŸ¥çœ‹ç”Ÿæˆçš„è¯Šæ–­æŠ¥å‘Š\")\nprint(\"  2. å‚è€ƒcomprehensive_guide.ipynb\")\nprint(\"  3. å¯»æ±‚ç¤¾åŒºæˆ–æŠ€æœ¯æ”¯æŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ è·å–æ›´å¤šå¸®åŠ©\n",
    "\n",
    "å¦‚æœæœ¬æ•…éšœæ’é™¤æŒ‡å—æ— æ³•è§£å†³æ‚¨çš„é—®é¢˜ï¼Œè¯·å°è¯•ä»¥ä¸‹èµ„æºï¼š\n",
    "\n",
    "### ğŸ“š å®˜æ–¹æ–‡æ¡£\n",
    "- [LangChainå®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)\n",
    "- [OpenAI APIæ–‡æ¡£](https://platform.openai.com/docs)\n",
    "- [Jupyteræ–‡æ¡£](https://jupyter.org/documentation)\n",
    "\n",
    "### ğŸ’¬ ç¤¾åŒºæ”¯æŒ\n",
    "- [LangChain GitHub](https://github.com/langchain-ai/langchain)\n",
    "- [Stack Overflow](https://stackoverflow.com/questions/tagged/langchain)\n",
    "- [Reddit r/MachineLearning](https://www.reddit.com/r/MachineLearning/)\n",
    "\n",
    "### ğŸ“ å­¦ä¹ èµ„æº\n",
    "- [DeepLearning.AIè¯¾ç¨‹](https://learn.deeplearning.ai/)\n",
    "- [LangChain YouTubeé¢‘é“](https://www.youtube.com/@LangChain)\n",
    "- [AIç›¸å…³åšå®¢å’Œæ•™ç¨‹](https://blog.langchain.dev/)\n",
    "\n",
    "### ğŸ› ï¸ å¼€å‘å·¥å…·\n",
    "- [LangSmithè°ƒè¯•å¹³å°](https://smith.langchain.com/)\n",
    "- [VS Code Pythonæ‰©å±•](https://marketplace.visualstudio.com/items?itemName=ms-python.python)\n",
    "- [GitHub Copilot](https://github.com/features/copilot)\n",
    "\n",
    "---\n",
    "\n",
    "**è®°ä½ï¼šé‡åˆ°é—®é¢˜æ˜¯å­¦ä¹ è¿‡ç¨‹çš„æ­£å¸¸éƒ¨åˆ†ï¼Œä¿æŒè€å¿ƒå’Œå­¦ä¹ çš„çƒ­æƒ…ï¼** ğŸŒŸ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}