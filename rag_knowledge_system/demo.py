"""
RAGçŸ¥è¯†åº“ç³»ç»Ÿæ¼”ç¤ºè„šæœ¬

å±•ç¤ºå®Œæ•´çš„RAGç³»ç»Ÿå·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬æ–‡æ¡£å¤„ç†ã€å‘é‡å­˜å‚¨ã€æ£€ç´¢å’Œç”Ÿæˆã€‚
"""

import os
import logging
from pathlib import Path
from typing import List

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æœ¬åœ°å¯¼å…¥
from src.document_processor import DocumentProcessor, ProcessingConfig
from src.vectorstore import VectorStoreManager, EmbeddingConfig
from src.retrieval import create_hybrid_retriever, RetrievalConfig
from src.generation import RAGChain, PromptManager


def setup_demo_environment():
    """è®¾ç½®æ¼”ç¤ºç¯å¢ƒ"""
    # åˆ›å»ºæ¼”ç¤ºæ•°æ®ç›®å½•
    demo_dir = Path("./demo_data")
    demo_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºç¤ºä¾‹æ–‡æ¡£
    sample_docs = [
        {
            "title": "äººå·¥æ™ºèƒ½ç®€ä»‹",
            "content": """
            äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚
            è¿™äº›ä»»åŠ¡åŒ…æ‹¬å­¦ä¹ ã€æ¨ç†ã€æ„ŸçŸ¥ã€è¯­è¨€ç†è§£å’Œé—®é¢˜è§£å†³ã€‚
            
            AIçš„ä¸»è¦æŠ€æœ¯åŒ…æ‹¬æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰ã€‚
            æœºå™¨å­¦ä¹ è®©è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ ï¼Œè€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚
            æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚
            """
        },
        {
            "title": "æœºå™¨å­¦ä¹ åŸºç¡€",
            "content": """
            æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯ä¹‹ä¸€ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ å’Œæ”¹è¿›æ€§èƒ½ã€‚
            ä¸»è¦æœ‰ä¸‰ç§ç±»å‹çš„æœºå™¨å­¦ä¹ ï¼šç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ã€‚
            
            ç›‘ç£å­¦ä¹ ä½¿ç”¨æ ‡è®°çš„è®­ç»ƒæ•°æ®æ¥å­¦ä¹ è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚
            æ— ç›‘ç£å­¦ä¹ ä»æœªæ ‡è®°çš„æ•°æ®ä¸­å‘ç°éšè—çš„æ¨¡å¼ã€‚
            å¼ºåŒ–å­¦ä¹ é€šè¿‡ä¸ç¯å¢ƒçš„äº¤äº’æ¥å­¦ä¹ æœ€ä¼˜è¡Œä¸ºç­–ç•¥ã€‚
            
            å¸¸è§çš„æœºå™¨å­¦ä¹ ç®—æ³•åŒ…æ‹¬çº¿æ€§å›å½’ã€å†³ç­–æ ‘ã€éšæœºæ£®æ—ã€æ”¯æŒå‘é‡æœºå’Œç¥ç»ç½‘ç»œã€‚
            """
        },
        {
            "title": "æ·±åº¦å­¦ä¹ åº”ç”¨",
            "content": """
            æ·±åº¦å­¦ä¹ åœ¨è®¸å¤šé¢†åŸŸéƒ½æœ‰é‡è¦åº”ç”¨ã€‚åœ¨è®¡ç®—æœºè§†è§‰ä¸­ï¼Œå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰
            ç”¨äºå›¾åƒè¯†åˆ«ã€ç‰©ä½“æ£€æµ‹å’Œå›¾åƒåˆ†ç±»ã€‚
            
            åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼Œå¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å’ŒTransformeræ¨¡å‹ç”¨äº
            æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬ç”Ÿæˆå’Œæƒ…æ„Ÿåˆ†æã€‚
            
            æ·±åº¦å­¦ä¹ è¿˜åœ¨è¯­éŸ³è¯†åˆ«ã€æ¨èç³»ç»Ÿã€åŒ»å­¦è¯Šæ–­å’Œè‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸ
            å‘æŒ¥ç€é‡è¦ä½œç”¨ã€‚æœ€è¿‘çš„çªç ´åŒ…æ‹¬GPTç³»åˆ—ã€BERTå’Œå…¶ä»–å¤§å‹è¯­è¨€æ¨¡å‹ã€‚
            """
        },
        {
            "title": "RAGæŠ€æœ¯è¯¦è§£",
            "content": """
            æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ˜¯ä¸€ç§ç»“åˆä¿¡æ¯æ£€ç´¢å’Œæ–‡æœ¬ç”Ÿæˆçš„AIæŠ€æœ¯ã€‚
            å®ƒé¦–å…ˆä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œç„¶åä½¿ç”¨è¿™äº›ä¿¡æ¯æ¥ç”Ÿæˆæ›´å‡†ç¡®çš„å›ç­”ã€‚
            
            RAGç³»ç»Ÿé€šå¸¸åŒ…å«ä¸‰ä¸ªä¸»è¦ç»„ä»¶ï¼šæ–‡æ¡£ç´¢å¼•å™¨ã€æ£€ç´¢å™¨å’Œç”Ÿæˆå™¨ã€‚
            æ–‡æ¡£ç´¢å¼•å™¨å°†çŸ¥è¯†åº“è½¬æ¢ä¸ºå¯æœç´¢çš„å‘é‡è¡¨ç¤ºã€‚
            æ£€ç´¢å™¨æ ¹æ®æŸ¥è¯¢æ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µã€‚
            ç”Ÿæˆå™¨ä½¿ç”¨æ£€ç´¢åˆ°çš„ä¿¡æ¯æ¥ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚
            
            RAGçš„ä¼˜åŠ¿åŒ…æ‹¬å‡å°‘å¹»è§‰ã€æä¾›å¯è¿½æº¯çš„ç­”æ¡ˆæ¥æºã€æ”¯æŒçŸ¥è¯†æ›´æ–°ã€‚
            """
        }
    ]
    
    # ä¿å­˜ç¤ºä¾‹æ–‡æ¡£
    for i, doc in enumerate(sample_docs):
        doc_path = demo_dir / f"doc_{i+1}.txt"
        with open(doc_path, 'w', encoding='utf-8') as f:
            f.write(f"# {doc['title']}\n\n{doc['content']}")
    
    logger.info(f"æ¼”ç¤ºç¯å¢ƒå‡†å¤‡å®Œæˆï¼Œåˆ›å»ºäº† {len(sample_docs)} ä¸ªç¤ºä¾‹æ–‡æ¡£")
    return demo_dir


def demo_document_processing(demo_dir: Path):
    """æ¼”ç¤ºæ–‡æ¡£å¤„ç†åŠŸèƒ½"""
    logger.info("=== æ–‡æ¡£å¤„ç†æ¼”ç¤º ===")
    
    # é…ç½®æ–‡æ¡£å¤„ç†å™¨
    config = ProcessingConfig(
        chunk_size=500,
        chunk_overlap=50,
        extract_metadata=True,
        generate_summary=True
    )
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = DocumentProcessor(config)
    
    # å¤„ç†æ–‡æ¡£ç›®å½•
    results = processor.process_directory(demo_dir, parallel=False)
    
    # æ”¶é›†æ‰€æœ‰å¤„ç†åçš„æ–‡æ¡£
    all_documents = []
    for result in results:
        if result.success:
            all_documents.extend(result.documents)
    
    logger.info(f"æ–‡æ¡£å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(all_documents)} ä¸ªæ–‡æ¡£å—")
    
    # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡
    stats = processor.get_stats()
    logger.info(f"å¤„ç†ç»Ÿè®¡: {stats}")
    
    return all_documents


def demo_vector_storage(documents):
    """æ¼”ç¤ºå‘é‡å­˜å‚¨åŠŸèƒ½"""
    logger.info("=== å‘é‡å­˜å‚¨æ¼”ç¤º ===")
    
    # é…ç½®åµŒå…¥æ¨¡å‹ï¼ˆä½¿ç”¨HuggingFaceä½œä¸ºæ¼”ç¤ºï¼‰
    embedding_config = EmbeddingConfig(
        provider="sentence_transformers",
        model_name="all-MiniLM-L6-v2",
        batch_size=32
    )
    
    # åˆ›å»ºå‘é‡å­˜å‚¨ç®¡ç†å™¨
    vector_manager = VectorStoreManager(
        collection_name="demo_knowledge_base",
        store_type="chroma",
        embedding_config=embedding_config,
        persist_directory="./demo_data/vectorstore"
    )
    
    # æ·»åŠ æ–‡æ¡£
    doc_ids = vector_manager.add_documents(documents)
    logger.info(f"å‘é‡å­˜å‚¨å®Œæˆï¼Œæ·»åŠ äº† {len(doc_ids)} ä¸ªæ–‡æ¡£")
    
    # æµ‹è¯•æœç´¢
    test_query = "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ"
    search_results = vector_manager.search(test_query, k=3)
    
    logger.info(f"æµ‹è¯•æœç´¢: '{test_query}'")
    logger.info(f"æ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³æ–‡æ¡£")
    
    return vector_manager


def demo_hybrid_retrieval(vector_manager, documents):
    """æ¼”ç¤ºæ··åˆæ£€ç´¢åŠŸèƒ½"""
    logger.info("=== æ··åˆæ£€ç´¢æ¼”ç¤º ===")
    
    # åˆ›å»ºæ··åˆæ£€ç´¢å™¨
    retrieval_config = RetrievalConfig(
        k=5,
        similarity_threshold=0.3
    )
    
    hybrid_retriever = create_hybrid_retriever(
        vector_manager,
        documents,
        config=retrieval_config,
        vector_weight=0.7
    )
    
    # æµ‹è¯•æ£€ç´¢
    test_queries = [
        "äººå·¥æ™ºèƒ½çš„ä¸»è¦æŠ€æœ¯æœ‰å“ªäº›ï¼Ÿ",
        "æœºå™¨å­¦ä¹ çš„ç±»å‹",
        "RAGæŠ€æœ¯çš„ä¼˜åŠ¿",
        "æ·±åº¦å­¦ä¹ åœ¨å“ªäº›é¢†åŸŸåº”ç”¨ï¼Ÿ"
    ]
    
    for query in test_queries:
        logger.info(f"\næŸ¥è¯¢: {query}")
        
        result = hybrid_retriever.retrieve(query, k=3)
        
        logger.info(f"æ£€ç´¢åˆ° {len(result.documents)} ä¸ªæ–‡æ¡£")
        for i, doc in enumerate(result.documents[:2]):  # åªæ˜¾ç¤ºå‰2ä¸ª
            logger.info(f"  æ–‡æ¡£ {i+1}: {doc.page_content[:100]}...")
    
    return hybrid_retriever


def demo_mock_llm():
    """åˆ›å»ºæ¨¡æ‹ŸLLMç”¨äºæ¼”ç¤º"""
    class MockLLM:
        def invoke(self, prompt):
            # ç®€å•çš„æ¨¡æ‹Ÿå“åº”
            if "ä»€ä¹ˆæ˜¯" in prompt or "What is" in prompt:
                return MockResponse("è¿™æ˜¯ä¸€ä¸ªåŸºäºæ£€ç´¢ä¿¡æ¯ç”Ÿæˆçš„å›ç­”ã€‚æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œ...")
            elif "ç±»å‹" in prompt or "types" in prompt:
                return MockResponse("æ ¹æ®æ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼Œä¸»è¦æœ‰ä»¥ä¸‹å‡ ç§ç±»å‹ï¼š1. ... 2. ... 3. ...")
            elif "ä¼˜åŠ¿" in prompt or "advantages" in prompt:
                return MockResponse("åŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼Œä¸»è¦ä¼˜åŠ¿åŒ…æ‹¬ï¼š...")
            else:
                return MockResponse("æ ¹æ®æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›ä»¥ä¸‹å›ç­”ï¼š...")
    
    class MockResponse:
        def __init__(self, content):
            self.content = content
    
    return MockLLM()


def demo_rag_generation(retriever):
    """æ¼”ç¤ºRAGç”ŸæˆåŠŸèƒ½"""
    logger.info("=== RAGç”Ÿæˆæ¼”ç¤º ===")
    
    # åˆ›å»ºæ¨¡æ‹ŸLLM
    mock_llm = demo_mock_llm()
    
    # åˆ›å»ºRAGé“¾
    rag_chain = RAGChain(
        llm=mock_llm,
        retriever=retriever,
        max_context_length=2000,
        include_sources=True
    )
    
    # æµ‹è¯•é—®ç­”
    test_questions = [
        "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        "æœºå™¨å­¦ä¹ æœ‰å“ªäº›ç±»å‹ï¼Ÿ",
        "RAGæŠ€æœ¯æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ",
        "æ·±åº¦å­¦ä¹ åœ¨å“ªäº›é¢†åŸŸæœ‰åº”ç”¨ï¼Ÿ"
    ]
    
    for question in test_questions:
        logger.info(f"\né—®é¢˜: {question}")
        
        response = rag_chain.run(question, k=3)
        
        logger.info(f"å›ç­”: {response.answer}")
        logger.info(f"ç½®ä¿¡åº¦: {response.confidence_score:.2f}")
        logger.info(f"å“åº”æ—¶é—´: {response.generation_time:.2f}ç§’")
        logger.info(f"ä½¿ç”¨äº† {len(response.source_documents)} ä¸ªå‚è€ƒæ–‡æ¡£")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    stats = rag_chain.get_stats()
    logger.info(f"\nRAGç»Ÿè®¡: {stats}")


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹RAGçŸ¥è¯†åº“ç³»ç»Ÿæ¼”ç¤º")
    
    try:
        # 1. è®¾ç½®ç¯å¢ƒ
        demo_dir = setup_demo_environment()
        
        # 2. æ–‡æ¡£å¤„ç†
        documents = demo_document_processing(demo_dir)
        
        # 3. å‘é‡å­˜å‚¨
        vector_manager = demo_vector_storage(documents)
        
        # 4. æ··åˆæ£€ç´¢
        hybrid_retriever = demo_hybrid_retrieval(vector_manager, documents)
        
        # 5. RAGç”Ÿæˆ
        demo_rag_generation(hybrid_retriever)
        
        logger.info("\nâœ… RAGçŸ¥è¯†åº“ç³»ç»Ÿæ¼”ç¤ºå®Œæˆï¼")
        
        # ç³»ç»Ÿä¿¡æ¯
        logger.info("\n=== ç³»ç»Ÿä¿¡æ¯ ===")
        collection_info = vector_manager.get_collection_info()
        logger.info(f"é›†åˆä¿¡æ¯: {collection_info}")
        
        retrieval_stats = hybrid_retriever.get_stats()
        logger.info(f"æ£€ç´¢ç»Ÿè®¡: {retrieval_stats}")
        
    except Exception as e:
        logger.error(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        raise


if __name__ == "__main__":
    main()