"""
æ–‡æœ¬å¤„ç†å·¥å…·æ¨¡å—çš„å•å…ƒæµ‹è¯•

æµ‹è¯•text_utilsä¸­çš„å„ç§æ–‡æœ¬å¤„ç†å‡½æ•°ã€‚
"""

import pytest
from langchain_learning.utils.text_utils import (
    clean_text,
    truncate_text,
    split_text,
    extract_keywords,
    detect_language,
    calculate_text_similarity,
    format_text_for_display,
    escape_special_chars,
    generate_text_hash,
    encode_decode_text,
    extract_urls,
    extract_emails,
    extract_phone_numbers,
    word_count,
    generate_summary
)


class TestCleanText:
    """æµ‹è¯•æ–‡æœ¬æ¸…æ´—åŠŸèƒ½"""
    
    def test_basic_cleaning(self):
        """æµ‹è¯•åŸºæœ¬æ¸…æ´—"""
        text = "  Hello   World  \n\n  "
        result = clean_text(text)
        assert result == "Hello World"
    
    def test_html_unescape(self):
        """æµ‹è¯•HTMLå®ä½“åè½¬ä¹‰"""
        text = "&lt;div&gt;Hello &amp; World&lt;/div&gt;"
        result = clean_text(text, unescape_html=True)
        assert "<div>" in result
        assert "&" in result
    
    def test_newline_removal(self):
        """æµ‹è¯•æ¢è¡Œç¬¦ç§»é™¤"""
        text = "Line 1\nLine 2\r\nLine 3"
        result = clean_text(text, remove_newlines=True)
        assert "\n" not in result
        assert "\r" not in result
        assert "Line 1 Line 2 Line 3" == result
    
    def test_unicode_normalization(self):
        """æµ‹è¯•Unicodeæ ‡å‡†åŒ–"""
        text = "cafÃ©"  # å¯èƒ½åŒ…å«ç»„åˆå­—ç¬¦
        result = clean_text(text, normalize_unicode=True)
        # åº”è¯¥æ ‡å‡†åŒ–ä¸ºé¢„ç»„åˆå½¢å¼
        assert result == "cafÃ©"
    
    def test_empty_text(self):
        """æµ‹è¯•ç©ºæ–‡æœ¬"""
        assert clean_text("") == ""
        assert clean_text(None) == ""


class TestTruncateText:
    """æµ‹è¯•æ–‡æœ¬æˆªæ–­åŠŸèƒ½"""
    
    def test_basic_truncation(self):
        """æµ‹è¯•åŸºæœ¬æˆªæ–­"""
        text = "This is a long sentence that needs to be truncated"
        result = truncate_text(text, max_length=20)
        assert len(result) <= 20
        assert result.endswith("...")
    
    def test_preserve_words(self):
        """æµ‹è¯•ä¿æŒå•è¯å®Œæ•´æ€§"""
        text = "This is a test sentence"
        result = truncate_text(text, max_length=15, preserve_words=True)
        # åº”è¯¥åœ¨å•è¯è¾¹ç•Œæˆªæ–­
        assert not result.split()[-1].startswith("...")  # æœ€åä¸€ä¸ªè¯åº”è¯¥æ˜¯å®Œæ•´çš„ï¼ˆé™¤äº†çœç•¥å·ï¼‰
    
    def test_no_truncation_needed(self):
        """æµ‹è¯•ä¸éœ€è¦æˆªæ–­çš„æƒ…å†µ"""
        text = "Short text"
        result = truncate_text(text, max_length=20)
        assert result == text
    
    def test_custom_suffix(self):
        """æµ‹è¯•è‡ªå®šä¹‰åç¼€"""
        text = "This is a long text"
        result = truncate_text(text, max_length=15, suffix="[...]")
        assert result.endswith("[...]")


class TestSplitText:
    """æµ‹è¯•æ–‡æœ¬åˆ†å‰²åŠŸèƒ½"""
    
    def test_basic_split(self):
        """æµ‹è¯•åŸºæœ¬åˆ†å‰²"""
        text = "This is a test. " * 100  # åˆ›å»ºé•¿æ–‡æœ¬
        chunks = split_text(text, chunk_size=50)
        
        assert len(chunks) > 1
        for chunk in chunks:
            assert len(chunk) <= 50 or len(chunk.split()) == 1  # é™¤éæ˜¯å•ä¸ªé•¿å•è¯
    
    def test_split_by_paragraphs(self):
        """æµ‹è¯•æŒ‰æ®µè½åˆ†å‰²"""
        text = "Paragraph 1.\n\nParagraph 2.\n\nParagraph 3."
        chunks = split_text(text, chunk_size=15, separators=['\n\n', '. '])
        
        # åº”è¯¥ä¼˜å…ˆåœ¨æ®µè½è¾¹ç•Œåˆ†å‰²
        assert len(chunks) >= 3
    
    def test_chunk_overlap(self):
        """æµ‹è¯•å—é‡å """
        text = "First sentence. Second sentence. Third sentence. Fourth sentence."
        chunks = split_text(text, chunk_size=30, chunk_overlap=10)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å å†…å®¹
        if len(chunks) > 1:
            # ç¬¬äºŒä¸ªå—åº”è¯¥åŒ…å«ç¬¬ä¸€ä¸ªå—çš„éƒ¨åˆ†å†…å®¹
            assert any(word in chunks[1] for word in chunks[0].split()[-3:])
    
    def test_empty_text(self):
        """æµ‹è¯•ç©ºæ–‡æœ¬"""
        assert split_text("") == []
        assert split_text(None) == []


class TestExtractKeywords:
    """æµ‹è¯•å…³é”®è¯æå–åŠŸèƒ½"""
    
    def test_basic_extraction(self):
        """æµ‹è¯•åŸºæœ¬å…³é”®è¯æå–"""
        text = "Python is a powerful programming language. Python is easy to learn."
        keywords = extract_keywords(text, top_k=5)
        
        assert "python" in keywords  # åº”è¯¥è½¬æ¢ä¸ºå°å†™
        assert len(keywords) <= 5
    
    def test_exclude_stopwords(self):
        """æµ‹è¯•æ’é™¤åœç”¨è¯"""
        text = "The quick brown fox jumps over the lazy dog"
        keywords = extract_keywords(text, exclude_stopwords=True)
        
        # åœç”¨è¯åº”è¯¥è¢«æ’é™¤
        assert "the" not in keywords
        assert "over" not in keywords
        # å®é™…å•è¯åº”è¯¥è¢«ä¿ç•™
        assert "quick" in keywords or "brown" in keywords
    
    def test_length_filtering(self):
        """æµ‹è¯•é•¿åº¦è¿‡æ»¤"""
        text = "A very long supercalifragilisticexpialidocious word test"
        keywords = extract_keywords(text, min_length=4, max_length=10)
        
        # å¤ªçŸ­æˆ–å¤ªé•¿çš„è¯åº”è¯¥è¢«è¿‡æ»¤
        for keyword in keywords:
            assert 4 <= len(keyword) <= 10
    
    def test_chinese_text(self):
        """æµ‹è¯•ä¸­æ–‡æ–‡æœ¬"""
        text = "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œäººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•å¾ˆå¿«"
        keywords = extract_keywords(text, top_k=3)
        
        assert len(keywords) > 0
        # åº”è¯¥åŒ…å«ä¸€äº›ä¸­æ–‡å…³é”®è¯
        assert any(len(keyword) > 1 for keyword in keywords)


class TestDetectLanguage:
    """æµ‹è¯•è¯­è¨€æ£€æµ‹åŠŸèƒ½"""
    
    def test_chinese_detection(self):
        """æµ‹è¯•ä¸­æ–‡æ£€æµ‹"""
        text = "è¿™æ˜¯ä¸€æ®µä¸­æ–‡æ–‡æœ¬ï¼Œç”¨äºæµ‹è¯•è¯­è¨€æ£€æµ‹åŠŸèƒ½ã€‚"
        result = detect_language(text)
        assert result == "zh"
    
    def test_english_detection(self):
        """æµ‹è¯•è‹±æ–‡æ£€æµ‹"""
        text = "This is an English text for language detection testing."
        result = detect_language(text)
        assert result == "en"
    
    def test_japanese_detection(self):
        """æµ‹è¯•æ—¥æ–‡æ£€æµ‹"""
        text = "ã“ã‚Œã¯æ—¥æœ¬èªã®ãƒ†ã‚¹ãƒˆã§ã™ã€‚ã²ã‚‰ãŒãªã¨ã‚«ã‚¿ã‚«ãƒŠãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚"
        result = detect_language(text)
        assert result == "ja"
    
    def test_mixed_language(self):
        """æµ‹è¯•æ··åˆè¯­è¨€"""
        text = "Hello ä½ å¥½ world ä¸–ç•Œ"
        result = detect_language(text)
        # åº”è¯¥æ£€æµ‹å‡ºå æ¯”è¾ƒé«˜çš„è¯­è¨€
        assert result in ["zh", "en"]
    
    def test_empty_text(self):
        """æµ‹è¯•ç©ºæ–‡æœ¬"""
        assert detect_language("") == "unknown"
        assert detect_language(None) == "unknown"


class TestCalculateTextSimilarity:
    """æµ‹è¯•æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—"""
    
    def test_identical_texts(self):
        """æµ‹è¯•ç›¸åŒæ–‡æœ¬"""
        text = "This is a test sentence"
        similarity = calculate_text_similarity(text, text)
        assert similarity == 1.0
    
    def test_completely_different_texts(self):
        """æµ‹è¯•å®Œå…¨ä¸åŒçš„æ–‡æœ¬"""
        text1 = "apple banana cherry"
        text2 = "dog elephant fox"
        similarity = calculate_text_similarity(text1, text2)
        assert similarity == 0.0
    
    def test_partially_similar_texts(self):
        """æµ‹è¯•éƒ¨åˆ†ç›¸ä¼¼çš„æ–‡æœ¬"""
        text1 = "the quick brown fox"
        text2 = "the slow brown dog"
        similarity = calculate_text_similarity(text1, text2)
        assert 0 < similarity < 1
    
    def test_jaccard_vs_cosine(self):
        """æµ‹è¯•ä¸åŒç›¸ä¼¼åº¦ç®—æ³•"""
        text1 = "hello world test"
        text2 = "hello test example"
        
        jaccard = calculate_text_similarity(text1, text2, method="jaccard")
        cosine = calculate_text_similarity(text1, text2, method="cosine")
        
        assert 0 <= jaccard <= 1
        assert 0 <= cosine <= 1
    
    def test_empty_texts(self):
        """æµ‹è¯•ç©ºæ–‡æœ¬"""
        assert calculate_text_similarity("", "test") == 0.0
        assert calculate_text_similarity("test", "") == 0.0
        assert calculate_text_similarity("", "") == 0.0


class TestFormatTextForDisplay:
    """æµ‹è¯•æ–‡æœ¬æ˜¾ç¤ºæ ¼å¼åŒ–"""
    
    def test_basic_formatting(self):
        """æµ‹è¯•åŸºæœ¬æ ¼å¼åŒ–"""
        text = "This is a long sentence that should be wrapped to multiple lines for better display"
        result = format_text_for_display(text, width=20)
        
        lines = result.split('\n')
        for line in lines:
            assert len(line) <= 20
    
    def test_indentation(self):
        """æµ‹è¯•ç¼©è¿›"""
        text = "Hello World"
        result = format_text_for_display(text, width=20, indent=4)
        
        lines = result.split('\n')
        for line in lines:
            if line.strip():  # éç©ºè¡Œ
                assert line.startswith("    ")
    
    def test_alignment(self):
        """æµ‹è¯•å¯¹é½"""
        text = "Center"
        result = format_text_for_display(text, width=20, align="center")
        
        # åº”è¯¥å±…ä¸­å¯¹é½
        assert result.strip() == text
        assert len(result) <= 20


class TestEscapeSpecialChars:
    """æµ‹è¯•ç‰¹æ®Šå­—ç¬¦è½¬ä¹‰"""
    
    def test_regex_escape(self):
        """æµ‹è¯•æ­£åˆ™è¡¨è¾¾å¼è½¬ä¹‰"""
        text = "Hello. (World) [Test] {Regex} ^$*+?|"
        result = escape_special_chars(text, escape_type="regex")
        
        # ç‰¹æ®Šå­—ç¬¦åº”è¯¥è¢«è½¬ä¹‰
        assert "\\." in result
        assert "\\(" in result
        assert "\\[" in result
    
    def test_html_escape(self):
        """æµ‹è¯•HTMLè½¬ä¹‰"""
        text = "<div>Hello & World</div>"
        result = escape_special_chars(text, escape_type="html")
        
        assert "&lt;" in result
        assert "&gt;" in result
        assert "&amp;" in result
    
    def test_url_escape(self):
        """æµ‹è¯•URLç¼–ç """
        text = "hello world@example.com"
        result = escape_special_chars(text, escape_type="url")
        
        assert "%20" in result  # ç©ºæ ¼åº”è¯¥è¢«ç¼–ç 
        assert "%40" in result  # @åº”è¯¥è¢«ç¼–ç 
    
    def test_json_escape(self):
        """æµ‹è¯•JSONè½¬ä¹‰"""
        text = 'Hello "World" \n Test'
        result = escape_special_chars(text, escape_type="json")
        
        assert '\\"' in result  # å¼•å·åº”è¯¥è¢«è½¬ä¹‰
        assert '\\n' in result  # æ¢è¡Œç¬¦åº”è¯¥è¢«è½¬ä¹‰


class TestGenerateTextHash:
    """æµ‹è¯•æ–‡æœ¬å“ˆå¸Œç”Ÿæˆ"""
    
    def test_md5_hash(self):
        """æµ‹è¯•MD5å“ˆå¸Œ"""
        text = "Hello World"
        hash_value = generate_text_hash(text, algorithm="md5")
        
        assert len(hash_value) == 32  # MD5å“ˆå¸Œé•¿åº¦
        assert hash_value.isalnum()  # åº”è¯¥æ˜¯åå…­è¿›åˆ¶
    
    def test_sha256_hash(self):
        """æµ‹è¯•SHA256å“ˆå¸Œ"""
        text = "Hello World"
        hash_value = generate_text_hash(text, algorithm="sha256")
        
        assert len(hash_value) == 64  # SHA256å“ˆå¸Œé•¿åº¦
    
    def test_consistent_hashing(self):
        """æµ‹è¯•å“ˆå¸Œä¸€è‡´æ€§"""
        text = "Test consistency"
        hash1 = generate_text_hash(text)
        hash2 = generate_text_hash(text)
        
        assert hash1 == hash2
    
    def test_different_texts_different_hashes(self):
        """æµ‹è¯•ä¸åŒæ–‡æœ¬äº§ç”Ÿä¸åŒå“ˆå¸Œ"""
        hash1 = generate_text_hash("Text 1")
        hash2 = generate_text_hash("Text 2")
        
        assert hash1 != hash2


class TestEncodeDecodeText:
    """æµ‹è¯•æ–‡æœ¬ç¼–ç è§£ç """
    
    def test_base64_encoding(self):
        """æµ‹è¯•Base64ç¼–ç """
        text = "Hello World ä½ å¥½ä¸–ç•Œ"
        encoded = encode_decode_text(text, encoding="base64", operation="encode")
        decoded = encode_decode_text(encoded, encoding="base64", operation="decode")
        
        assert decoded == text
    
    def test_hex_encoding(self):
        """æµ‹è¯•åå…­è¿›åˆ¶ç¼–ç """
        text = "Hello"
        encoded = encode_decode_text(text, encoding="hex", operation="encode")
        decoded = encode_decode_text(encoded, encoding="hex", operation="decode")
        
        assert decoded == text
        assert all(c in "0123456789abcdef" for c in encoded)
    
    def test_unicode_support(self):
        """æµ‹è¯•Unicodeæ”¯æŒ"""
        text = "æµ‹è¯•Unicodeç¼–ç  ğŸŒŸ"
        encoded = encode_decode_text(text, encoding="base64", operation="encode")
        decoded = encode_decode_text(encoded, encoding="base64", operation="decode")
        
        assert decoded == text


class TestExtractUrls:
    """æµ‹è¯•URLæå–"""
    
    def test_basic_url_extraction(self):
        """æµ‹è¯•åŸºæœ¬URLæå–"""
        text = "Visit https://example.com and http://test.org for more info"
        urls = extract_urls(text)
        
        assert "https://example.com" in urls
        assert "http://test.org" in urls
        assert len(urls) == 2
    
    def test_complex_urls(self):
        """æµ‹è¯•å¤æ‚URL"""
        text = "Check https://example.com/path?param=value&other=123#section"
        urls = extract_urls(text)
        
        assert len(urls) == 1
        assert "param=value" in urls[0]
        assert "#section" in urls[0]
    
    def test_no_urls(self):
        """æµ‹è¯•æ— URLæ–‡æœ¬"""
        text = "This text has no URLs in it"
        urls = extract_urls(text)
        
        assert len(urls) == 0


class TestExtractEmails:
    """æµ‹è¯•é‚®ç®±æå–"""
    
    def test_basic_email_extraction(self):
        """æµ‹è¯•åŸºæœ¬é‚®ç®±æå–"""
        text = "Contact us at test@example.com or support@company.org"
        emails = extract_emails(text)
        
        assert "test@example.com" in emails
        assert "support@company.org" in emails
        assert len(emails) == 2
    
    def test_complex_emails(self):
        """æµ‹è¯•å¤æ‚é‚®ç®±"""
        text = "Send to user.name+tag@sub.domain.com"
        emails = extract_emails(text)
        
        assert len(emails) == 1
        assert "user.name+tag@sub.domain.com" in emails
    
    def test_no_emails(self):
        """æµ‹è¯•æ— é‚®ç®±æ–‡æœ¬"""
        text = "This text has no email addresses"
        emails = extract_emails(text)
        
        assert len(emails) == 0


class TestExtractPhoneNumbers:
    """æµ‹è¯•ç”µè¯å·ç æå–"""
    
    def test_chinese_phone_numbers(self):
        """æµ‹è¯•ä¸­å›½æ‰‹æœºå·"""
        text = "æˆ‘çš„æ‰‹æœºå·æ˜¯13812345678ï¼Œè¯·è”ç³»æˆ‘"
        phones = extract_phone_numbers(text, country="cn")
        
        assert "13812345678" in phones
    
    def test_us_phone_numbers(self):
        """æµ‹è¯•ç¾å›½ç”µè¯å·ç """
        text = "Call me at (555) 123-4567 or 555.987.6543"
        phones = extract_phone_numbers(text, country="us")
        
        assert len(phones) >= 1  # è‡³å°‘æå–åˆ°ä¸€ä¸ª
    
    def test_no_phones(self):
        """æµ‹è¯•æ— ç”µè¯å·ç æ–‡æœ¬"""
        text = "This text has no phone numbers"
        phones = extract_phone_numbers(text)
        
        assert len(phones) == 0


class TestWordCount:
    """æµ‹è¯•è¯æ•°ç»Ÿè®¡"""
    
    def test_word_count(self):
        """æµ‹è¯•å•è¯è®¡æ•°"""
        text = "This is a test sentence with seven words"
        count = word_count(text, count_type="words")
        assert count == 8
    
    def test_character_count(self):
        """æµ‹è¯•å­—ç¬¦è®¡æ•°"""
        text = "Hello"
        count = word_count(text, count_type="characters")
        assert count == 5
    
    def test_character_count_no_spaces(self):
        """æµ‹è¯•ä¸å«ç©ºæ ¼çš„å­—ç¬¦è®¡æ•°"""
        text = "Hello World"
        count = word_count(text, count_type="characters_no_spaces")
        assert count == 10  # ä¸åŒ…å«ç©ºæ ¼
    
    def test_line_count(self):
        """æµ‹è¯•è¡Œæ•°ç»Ÿè®¡"""
        text = "Line 1\nLine 2\nLine 3"
        count = word_count(text, count_type="lines")
        assert count == 3


class TestGenerateSummary:
    """æµ‹è¯•æ‘˜è¦ç”Ÿæˆ"""
    
    def test_basic_summary(self):
        """æµ‹è¯•åŸºæœ¬æ‘˜è¦ç”Ÿæˆ"""
        text = (
            "This is the first sentence. "
            "This is the second sentence. "
            "This is the third sentence. "
            "This is the fourth sentence. "
            "This is the fifth sentence."
        )
        summary = generate_summary(text, max_sentences=2)
        
        # æ‘˜è¦åº”è¯¥åŒ…å«åŸæ–‡çš„éƒ¨åˆ†å†…å®¹
        assert len(summary) < len(text)
        assert "sentence" in summary
    
    def test_short_text_summary(self):
        """æµ‹è¯•çŸ­æ–‡æœ¬æ‘˜è¦"""
        text = "This is a short text."
        summary = generate_summary(text, max_sentences=3)
        
        # çŸ­æ–‡æœ¬åº”è¯¥è¿”å›åŸæ–‡
        assert summary == text
    
    def test_empty_text_summary(self):
        """æµ‹è¯•ç©ºæ–‡æœ¬æ‘˜è¦"""
        assert generate_summary("") == ""
        assert generate_summary(None) == ""